{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "aab6798a-71e9-4acd-a8e3-67bdf4ea84ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from helpers import parse_feature_metadata\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please set this constant to false if you wish the cells not to plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_GRAPHS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ffd2c",
   "metadata": {},
   "source": [
    "Local paths should be correct if repository was cloned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "f61ae2dd-4233-41ac-a1d7-f3605d64a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPAL_PATH = r\"data\\raw_updated_names\\nepal_new_feature_names.xlsx\"\n",
    "SENEGAL_PATH = r\"data\\raw_updated_names\\senegal_new_feature_names.xlsx\"\n",
    "\n",
    "nepal_df = pd.read_excel(NEPAL_PATH, index_col=0)\n",
    "senegal_df = pd.read_excel(SENEGAL_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75112d0-013b-4f50-bda8-42f2bce41966",
   "metadata": {},
   "source": [
    "## 1. Initial Parsing of the Data\n",
    "This phase includes removal of features that we from the start knew we would not use or would not be beneficial, and also coerces the remaining features's values to be their declared types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "b6fd9986-4d7f-4d05-8373-ac1ca0405c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPAL_CAT_COL_NAMES = {'Q11': 'Marital_Status',\n",
    " 'Q53': 'What_type_of_crop_is_grown_on_this_plot',\n",
    " 'Q54': 'For_vegetables_what_is_your_source_of_seeds',\n",
    " 'Q56': 'For_vegetables_do_you_use_seedlings',\n",
    " 'Q58': 'fertilizer_on_this_plot',\n",
    " 'Q63': 'What_is_the_main_use_of_produce_from_holding',\n",
    " 'Q64': 'Do_you_use_machinery_or_and_equipment_on_the_plot',\n",
    " 'Q65': 'Do_you_do_any_of_the_following',\n",
    " 'Q67': 'What_do_you_use_soil_analysis_for',\n",
    " 'Q68': 'How_do_you_conduct_soil_analysis',\n",
    " 'Q69': 'What_is_correct_for_you',\n",
    " 'Q71': 'in_the_past_12_months_from_who_did_you_receive_info_on_agriculture',\n",
    " 'Q73': 'Did_you_receive_anything_from_these_organizations',\n",
    " 'Q74': 'How_do_you_decide_to_plow',\n",
    " 'Q75': 'How_do_you_decide_to_begin_sowing',\n",
    " 'Q76': 'What_type_of_irrigation_do_you_use',\n",
    " 'Q100': 'Caste',\n",
    " 'Q105': 'main_sources_of_income',\n",
    " 'Q111': 'Generally_speaking_would_you_say_that_most_people_can_be_trusted',\n",
    " 'Q112': 'I_am_much_better_than_most_farmers_here',\n",
    " 'Q113': 'dislike_not_knowing_what_is_going_to_happen'}\n",
    "\n",
    "SENEGAL_CAT_COL_NAMES = {'Q63': 'CROP',\n",
    " 'Q64': 'Seed_source',\n",
    " 'Q65': 'Variety',\n",
    " 'Q66': 'Seedlings',\n",
    " 'Q67': 'Fertilizer',\n",
    " 'Q72': 'Sold_VEG',\n",
    " 'Q73': 'Machinery',\n",
    " 'Q74': 'Practice',\n",
    " 'Q77': 'Info_source',\n",
    " 'Q79': 'Did_you_receive_anything_from_the_specified_organizations',\n",
    " 'Q80': 'Plow_weather',\n",
    " 'Q81': 'Sow',\n",
    " 'Q82': 'Irrigation',\n",
    " 'Q88': 'family_main_sources_income',\n",
    " 'Q89': 'education_level'}\n",
    "\n",
    "def fix_column_values(series: pd.Series, meta: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given a pandas Series and its parsed metadata,\n",
    "    coerce its values to the right type:\n",
    "      - continuous, ordinal → numeric (floats or ints; bad → NaN)\n",
    "      - nominal -> categorical\n",
    "      - binary → 0/1 integers   (anything non-zero → 1, missing -> NaN)\n",
    "      - time   → pandas datetime (bad → NaT)\n",
    "    \"\"\"\n",
    "    ftype = meta[\"type\"]\n",
    "    fname = meta[\"name\"].lower()\n",
    "\n",
    "    if ftype in (\"continuous\", \"ordinal\"):\n",
    "        # numeric codes or measurements\n",
    "        return pd.to_numeric(series, errors=\"coerce\")\n",
    "    if ftype == \"nominal\":\n",
    "        return series.astype(\"category\")\n",
    "    if \"binary\" in ftype:\n",
    "        # strings that are not '0': → 1, otherwise __> 0, floats/ints: non-zero → 1, zero or NaN → 0\n",
    "        def to_binary(x):\n",
    "            if pd.isna(x):\n",
    "                return pd.NA\n",
    "            if isinstance(x, str):\n",
    "                return x != '0'\n",
    "            try:\n",
    "                return 1 if float(x) != 0 else 0\n",
    "            except:\n",
    "                return 1\n",
    "        return series.map(to_binary).astype(\"Int64\")\n",
    "\n",
    "    if ftype == \"time\":\n",
    "        # Force everything to str so we have uniform input\n",
    "        s = series.astype(str)\n",
    "        # 0) special: End_Date holds a full datetime → extract only the time\n",
    "        if \"end_date\" in fname:\n",
    "            # parses strings like \"4/27/2018 9:47:17 AM\" into Timestamps\n",
    "            dt = pd.to_datetime(s, errors=\"coerce\")\n",
    "            # grab Python datetime.time\n",
    "            return dt.dt.time\n",
    "        # 1) true date column → datetime64\n",
    "        if \"date\" in fname:\n",
    "            return pd.to_datetime(s, format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "        # 2) survey‐length durations → timedelta64\n",
    "        if \"length\" in fname:\n",
    "            # strings like \"00:21:14\" → Timedelta\n",
    "            return pd.to_timedelta(s, errors=\"coerce\")\n",
    "\n",
    "        # 3) the two pure clock‐time columns → Python time\n",
    "        #    strings like \"11:27:52\" → Timestamp → .time()\n",
    "        parsed = pd.to_datetime(s, format=\"%H:%M:%S\", errors=\"coerce\")\n",
    "        return parsed.dt.time\n",
    "\n",
    "    # otherwise leave it alone\n",
    "    return series\n",
    "\n",
    "\n",
    "def clean_survey_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a copy of df in which:\n",
    "      - all columns named Q<digits>__… have been coerced to their declared types\n",
    "      - all other columns are left untouched (you can drop them later)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        meta = parse_feature_metadata(col)\n",
    "        if meta is None:\n",
    "            continue\n",
    "        df[col] = fix_column_values(df[col], meta)\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_non_relevant_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove everything except Q<digits> columns:\n",
    "    \"\"\"\n",
    "    keep = [col for col in df.columns if parse_feature_metadata(col) is not None]\n",
    "    return df[keep]\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def combine_dummy_columns(orig_df: pd.DataFrame, names_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combines your binary dummy columns into single categorical columns,\n",
    "    but now *preserves* the option labels.\n",
    "\n",
    "    For each (qid, type):\n",
    "      - If there's exactly one dummy → just rename it to end in `-1`.\n",
    "      - If there are many and it's one-hot (max 1 per row) → new column takes the option LABEL, or None.\n",
    "      - Otherwise (multi-select) → new column is a list of the LABELS selected (possibly empty).\n",
    "    \"\"\"\n",
    "    df = orig_df.copy()\n",
    "\n",
    "    # 1) Gather metadata & group columns by (qid, type)\n",
    "    meta_map   = {}               # col_name → {qid, qname, var_type, dummy_idx, label}\n",
    "    buckets    = defaultdict(list)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if \"binary\" not in col:\n",
    "            continue\n",
    "        m = parse_feature_metadata(col)\n",
    "        qid        = m[\"qid\"]\n",
    "        qname      = m[\"name\"]\n",
    "        var_type   = m[\"type\"]\n",
    "        dummy_idx  = m[\"dummy\"]\n",
    "        \n",
    "        subnames = qname.split(':')\n",
    "        label      = qname\n",
    "\n",
    "        meta_map[col] = {\n",
    "            \"qid\":       qid,\n",
    "            \"qname\":     qname,\n",
    "            \"var_type\":  var_type,\n",
    "            \"dummy_idx\": dummy_idx,\n",
    "            \"label\":     label\n",
    "        }\n",
    "        buckets[(qid, var_type)].append(col)\n",
    "\n",
    "    to_drop  = []\n",
    "    new_cols = {}\n",
    "\n",
    "    # 2) Process each question group\n",
    "    for (qid, var_type), cols in buckets.items():\n",
    "        # sort by dummy_idx so labels stay in the right order\n",
    "        cols_sorted   = sorted(cols, key=lambda c: meta_map[c][\"dummy_idx\"])\n",
    "        labels_sorted = [meta_map[c][\"label\"] for c in cols_sorted]\n",
    "        arr           = df[cols_sorted].fillna(0).astype(int).values\n",
    "\n",
    "        # A) Single-dummy → just rename it to ...-1\n",
    "        if len(cols_sorted) == 1:\n",
    "            old = cols_sorted[0]\n",
    "            new = f\"{qid}__{meta_map[old]['qname']}__binary__1\"\n",
    "            df = df.rename(columns={old: new})\n",
    "            continue\n",
    "        \n",
    "\n",
    "        new_type = \"nominal\" if var_type.endswith(\"nominal\") else \"ordinal\"\n",
    "        qname = names_dict[qid]\n",
    "        new_name = f\"{qid}__{qname}__{new_type}\"\n",
    "        \n",
    "\n",
    "        # B) One-hot? (no row has more than one “1”)\n",
    "        if arr.sum(axis=1).max() <= 1:\n",
    "            cat = []\n",
    "            for row in arr:\n",
    "                if row.sum() == 0:\n",
    "                    cat.append(None)\n",
    "                else:\n",
    "                    cat.append(labels_sorted[row.argmax()])\n",
    "            \n",
    "            new_cols[new_name] = cat\n",
    "\n",
    "        # C) Multi-select\n",
    "        else:\n",
    "            multi = []\n",
    "            for row in arr:\n",
    "                # collect all the labels whose dummy==1\n",
    "                sel = [labels_sorted[i] for i, v in enumerate(row) if v == 1]\n",
    "                multi.append(tuple(sel))\n",
    "            new_cols[new_name] = multi\n",
    "\n",
    "        to_drop.extend(cols_sorted)\n",
    "\n",
    "    # 3) Drop old dummies & add the new columns\n",
    "    if to_drop:\n",
    "        df = df.drop(columns=to_drop)\n",
    "        df = pd.concat([df, pd.DataFrame(new_cols, index=df.index)], axis=1)\n",
    "\n",
    "    return df, new_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "6a2e67bc-2528-4ad9-b223-a92f9e7df7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping non Q#... columns\n",
    "nepal_df = drop_non_relevant_columns(nepal_df)\n",
    "senegal_df = drop_non_relevant_columns(senegal_df)\n",
    "\n",
    "# initial clean\n",
    "nepal_df = clean_survey_dataframe(nepal_df)\n",
    "senegal_df = clean_survey_dataframe(senegal_df)\n",
    "\n",
    "# combine and remove dummy columns\n",
    "nepal_df, npl_new_cols = combine_dummy_columns(nepal_df, NEPAL_CAT_COL_NAMES)\n",
    "senegal_df, sng_new_cols = combine_dummy_columns(senegal_df, SENEGAL_CAT_COL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21be13-c065-4f8f-b69b-ae3e7ddd1a7b",
   "metadata": {},
   "source": [
    "## Create Productivity Metric Columns (Targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "f0c4b03c-250e-40cf-9ab4-3fe169658f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_TO_SQM = 6772.63\n",
    "HEC_TO_SQM = 10_000\n",
    "XOF_TO_USD = 0.001871\n",
    "NP_TO_USD = 0.008851\n",
    "\n",
    "NPL_YEARLY_AGR_INCOME_COL = \"Q108__What_is_your_households_yearly_income_from_agriculture_NPR__continuous\"\n",
    "SNGL_YEARLY_AGR_INCOME_COL = 'Q90__Yearly_income_agriculture_XOF__continuous'\n",
    "NPL_OWND_CULTVTD_LAND_COL = \"Q50__How_much_land_that_is_yours_do_you_cultivate_bigha__continuous\"\n",
    "SNGL_OWND_CULTVTD_LAND_COL = \"Q60__Land_owned_cultivated_ha__continuous\"\n",
    "NPL_LEAS_CULTVTD_LAND_COL = \"Q51__How_much_land_that_is_rented_or_leased_do_you_cultivate_bigha__continuous\"\n",
    "SNGL_LEAS_CULTVTD_LAND_COL = \"Q61__Land_rented_cultivated_ha__continuous\"\n",
    "NPL_VEG_HARVEST_PER_YEAR_COL = \"Q62__How_much_VEGETABLES_do_you_harvest_per_year_from_this_plot_kilograms__continuous\"\n",
    "SNGL_VEG_HARVEST_PER_YEAR_COL = \"Q71__VEG_harvest_per_year_kg__continuous\"\n",
    "NPL_SELF_REPORTED_FARM_LEVEL_COL = \"Q112__Generally_speaking_how_would_you_define_your_farming__ordinal\"\n",
    "SNGL_SELF_REPORTED_FARM_LEVEL_COL = \"Q94__Farming_level_relative__ordinal\"\n",
    "NPL_VEG_LAND = \"Q52__On_how_much_land_do_you_grow_vegetables_bigha__continuous\"\n",
    "SNGL_VEG_LAND = \"Q62__Land_grow_vegetables_ha__continuous\"\n",
    "\n",
    "nepal_df['Q0__target1_yearly_income_from_agr_per_land_SQM__continuous'] = (NP_TO_USD * nepal_df[NPL_YEARLY_AGR_INCOME_COL]) / (BIG_TO_SQM * (nepal_df[NPL_OWND_CULTVTD_LAND_COL] + nepal_df[NPL_LEAS_CULTVTD_LAND_COL]))\n",
    "senegal_df['Q0__target1_yearly_income_from_agr_per_land_SQM__continuous'] = (XOF_TO_USD * senegal_df[SNGL_YEARLY_AGR_INCOME_COL]) / (HEC_TO_SQM * (senegal_df[SNGL_OWND_CULTVTD_LAND_COL] + senegal_df[SNGL_LEAS_CULTVTD_LAND_COL]))\n",
    "\n",
    "nepal_df['Q0__target2_yearly_income_from_agr_USD__continuous'] = NP_TO_USD * nepal_df[NPL_YEARLY_AGR_INCOME_COL]\n",
    "senegal_df['Q0__target2_yearly_income_from_agr_USD__continuous'] = XOF_TO_USD * senegal_df[SNGL_YEARLY_AGR_INCOME_COL]\n",
    "\n",
    "nepal_df['Q0__target3_veg_per_area__continuous'] = nepal_df[NPL_VEG_HARVEST_PER_YEAR_COL] / (BIG_TO_SQM * nepal_df[NPL_VEG_LAND])\n",
    "senegal_df['Q0__target3_veg_per_area__continuous'] = senegal_df[SNGL_VEG_HARVEST_PER_YEAR_COL] / (HEC_TO_SQM * senegal_df[SNGL_VEG_LAND])\n",
    "\n",
    "nepal_df.rename(columns={NPL_SELF_REPORTED_FARM_LEVEL_COL: 'Q0__target4_self_farming_perception__ordinal'}, inplace=True)\n",
    "senegal_df.rename(columns={SNGL_SELF_REPORTED_FARM_LEVEL_COL: 'Q0__target4_self_farming_perception__ordinal'}, inplace=True)\n",
    "\n",
    "# defragment\n",
    "nepal_df = nepal_df.copy()\n",
    "senegal_df = senegal_df.copy()\n",
    "\n",
    "target_cols = ['Q0__target1_yearly_income_from_agr_per_land_SQM__continuous',\n",
    "               'Q0__target2_yearly_income_from_agr_USD__continuous',\n",
    "               'Q0__target3_veg_per_area__continuous',\n",
    "               'Q0__target4_self_farming_perception__ordinal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21276580-c1c8-416a-8b09-ed65896e4f6e",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bdcf07-96ed-4c8f-9ff2-9f2a6401f884",
   "metadata": {},
   "source": [
    "## Analyze Datetime columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mew datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "4edcfa54-48ab-45d1-9878-094a95bdaf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nepal_df['Q2__SurveyedDate__time'] = pd.to_datetime(nepal_df['Q2__SurveyedDate__time'], errors='coerce')\n",
    "\n",
    "def create_datetime_col(df):\n",
    "    # ensure your date column is datetime64\n",
    "    df['Q2__SurveyedDate__time'] = pd.to_datetime(\n",
    "        df['Q2__SurveyedDate__time'], format=\"%Y-%m-%d\", errors='coerce'\n",
    "    )\n",
    "\n",
    "    # 1) build an all‐string “HH:MM:SS” series\n",
    "    time_str = df['Q2__SurveyedTime__time'].astype(str).str.extract(r'(\\d{2}:\\d{2}:\\d{2})')[0]\n",
    "\n",
    "    # 2) combine\n",
    "    dt_strings = df['Q2__SurveyedDate__time'].dt.strftime('%Y-%m-%d') + ' ' + time_str\n",
    "\n",
    "    # 3) parse into real timestamps\n",
    "    df['Q2__Surveyed_Date_Time__time'] = pd.to_datetime(dt_strings, errors='coerce')\n",
    "\n",
    "    print(df['Q2__Surveyed_Date_Time__time'].dtype)  # should be datetime64[ns]\n",
    "    \n",
    "create_datetime_col(nepal_df)\n",
    "create_datetime_col(senegal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed old one since already have DateTime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "82aa142c-1801-4e67-b489-36231346af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nepal_df = nepal_df.drop(['Q2__SurveyedDate__time', 'Q2__SurveyedTime__time'], axis=1)\n",
    "senegal_df = senegal_df.drop(['Q2__SurveyedDate__time', 'Q2__SurveyedTime__time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to analyze new datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "3b36661c-fad0-4194-aa29-352e7bdd0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_datetime(df, col):\n",
    "    \"\"\"\n",
    "    Perform univariate analysis on a datetime64 column:\n",
    "      - prints basic stats (min, max, missing)\n",
    "      - plots counts per day, month, weekday, and hour-of-day\n",
    "    \"\"\"\n",
    "    # Basic info\n",
    "    series = df[col]\n",
    "    if not series.dtype.name.startswith('datetime'):\n",
    "        raise ValueError(f\"Column {col!r} is not datetime dtype.\")\n",
    "    \n",
    "    print(f\"\\n--- ANALYSIS OF {col.upper()} ---\")\n",
    "    print(f\"Type: {series.dtype}\")\n",
    "    print(f\"Missing: {series.isna().sum()} / {len(series)}\")\n",
    "    print(f\"Range: {series.min()} → {series.max()}\")\n",
    "    \n",
    "    # Extract time features\n",
    "    df_temp = df.dropna(subset=[col]).copy()\n",
    "    df_temp['date']    = df_temp[col].dt.date\n",
    "    df_temp['month']   = df_temp[col].dt.to_period('M').astype(str)\n",
    "    df_temp['weekday'] = df_temp[col].dt.day_name()\n",
    "    df_temp['hour']    = df_temp[col].dt.hour\n",
    "    \n",
    "    # 1. Counts per day\n",
    "    daily = df_temp.groupby('date').size()\n",
    "    plt.figure()\n",
    "    daily.plot(kind='bar')\n",
    "    plt.title(f\"Number of Records per Day ({col})\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Counts by month\n",
    "    monthly = df_temp.groupby('month').size().sort_index()\n",
    "    plt.figure()\n",
    "    monthly.plot(kind='bar')\n",
    "    plt.title(f\"Counts by Month ({col})\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Counts by weekday\n",
    "    # ensure Mon–Sun order\n",
    "    weekdays = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "    wd = df_temp['weekday'].value_counts().reindex(weekdays)\n",
    "    plt.figure()\n",
    "    wd.plot(kind='bar')\n",
    "    plt.title(f\"Counts by Weekday ({col})\")\n",
    "    plt.xlabel(\"Weekday\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Distribution of hour of day\n",
    "    plt.figure()\n",
    "    sns.histplot(df_temp['hour'], bins=24, discrete=True, kde=False)\n",
    "    plt.title(f\"Survey Time of Day Distribution ({col})\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(range(0,24))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze new datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "a48af941-c391-4bc3-b0ac-ec18207c3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS: \n",
    "    print(\"NEPAL DATA\")\n",
    "    analyze_datetime(nepal_df, 'Q2__Surveyed_Date_Time__time')\n",
    "    print(\"SENEGAL DATA\")\n",
    "    analyze_datetime(senegal_df, 'Q2__Surveyed_Date_Time__time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38beb10c-62e6-4f5d-af05-8e8a00c0858c",
   "metadata": {},
   "source": [
    "## Analyze Survey Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Survey_Length column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "6a5f0c14-e60e-4877-9f6f-ae42c288fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# turn time → \"HH:MM:SS\" strings → Timedelta\n",
    "nepal_df['Q0__SurveyLengthTime__time'] = (\n",
    "    nepal_df['Q0__SurveyLengthTime__time']\n",
    "      .astype(str)                # datetime.time → \"HH:MM:SS\"\n",
    "      .pipe(pd.to_timedelta)      # parse into timedelta64[ns]\n",
    ")\n",
    "\n",
    "# first, make sure both your start‐ and end‐times are strings\n",
    "senegal_df['Q2__Surveyed_Date_Time__time'] = senegal_df['Q2__Surveyed_Date_Time__time'].astype(str)\n",
    "senegal_df['Q0__Surveyed_End_Date__time']   = senegal_df['Q0__Surveyed_End_Date__time'].astype(str)\n",
    "\n",
    "# 1) Parse your “start” column as a real timestamp\n",
    "senegal_df['start_dt'] = pd.to_datetime(\n",
    "    senegal_df['Q2__Surveyed_Date_Time__time'],\n",
    "    format='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# 2) Turn your “end time” (just HH:MM:SS) into a Timedelta\n",
    "senegal_df['end_td'] = pd.to_timedelta(\n",
    "    senegal_df['Q0__Surveyed_End_Date__time'].astype(str)\n",
    ")\n",
    "\n",
    "# 3) Build a full “end” timestamp by taking the date from start_dt and adding the time delta\n",
    "senegal_df['end_dt'] = (\n",
    "    senegal_df['start_dt'].dt.normalize()  # midnight of the start date\n",
    "  + senegal_df['end_td']\n",
    ")\n",
    "\n",
    "senegal_df['Q0__SurveyLengthTime__time'] = senegal_df['end_dt'] - senegal_df['start_dt']\n",
    "\n",
    "senegal_df.drop(columns=['start_dt', 'end_td', 'end_dt'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to analyze Survey_Length column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "efdded1a-ce51-4ca7-ae13-b8c828a996ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def analyze_survey_length(df, column='Q0__SurveyLengthTime__time', bins=30):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of survey lengths in a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the survey length column.\n",
    "    column : str, default 'Survey_Length'\n",
    "        Name of the timedelta column to analyze.\n",
    "    bins : int, default 30\n",
    "        Number of histogram bins.\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    - Histogram of survey lengths (HH:MM:SS) distribution.\n",
    "    - Printed mean and standard deviation of survey lengths.\n",
    "    - Returns a tuple (mean_timedelta, std_timedelta).\n",
    "    \"\"\"\n",
    "    # Ensure the column is timedelta64[ns]\n",
    "    if not pd.api.types.is_timedelta64_dtype(df[column]):\n",
    "        raise TypeError(f\"Column '{column}' must be timedelta64[ns] dtype\")\n",
    "\n",
    "    # Compute statistics\n",
    "    mean_td = df[column].mean()\n",
    "    std_td = df[column].std()\n",
    "\n",
    "    # Convert to total seconds for plotting\n",
    "    secs = df[column].dt.total_seconds()\n",
    "\n",
    "    # Plot histogram\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(secs, bins=bins)\n",
    "    ax.set_title(\"Distribution of Survey Lengths\")\n",
    "    ax.set_xlabel(\"Survey Length (HH:MM:SS)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "    # Formatter to convert seconds back to HH:MM:SS\n",
    "    def sec_to_hhmmss(x, pos):\n",
    "        h = int(x // 3600)\n",
    "        m = int((x % 3600) // 60)\n",
    "        s = int(x % 60)\n",
    "        return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(sec_to_hhmmss))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print mean and std in HH:MM:SS\n",
    "    mean_str = str(mean_td).split()[-1]\n",
    "    std_str  = str(std_td).split()[-1]\n",
    "    print(f\"Mean survey length: {mean_str}\")\n",
    "    print(f\"Std dev survey length: {std_str}\")\n",
    "\n",
    "    return mean_td, std_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "7e5c35ec-21a2-44fe-be73-b8376dd2daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    print(\"NEPAL DATA\")\n",
    "    analyze_survey_length(nepal_df)\n",
    "    print(\"SENEGAL DATA\")\n",
    "    analyze_survey_length(senegal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovered data-entry glitch extreme value at one Senegalese survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "570bc6e6-82fd-4f4f-8a5b-74eb374283b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Q2__Surveyed_Date_Time__time Q0__Surveyed_End_Date__time  \\\n",
      "328          2018-04-27 14:18:09                    00:11:33   \n",
      "\n",
      "    Q0__SurveyLengthTime__time  \n",
      "328          -1 days +09:53:24  \n"
     ]
    }
   ],
   "source": [
    "bad = senegal_df[ senegal_df['Q0__SurveyLengthTime__time'] < pd.Timedelta(0) ]\n",
    "print(bad[['Q2__Surveyed_Date_Time__time','Q0__Surveyed_End_Date__time','Q0__SurveyLengthTime__time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling in this survey with median survey length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "b8b4295a-8a1c-4d1c-944a-f134db186624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 negative Survey_Length(s), filling with median = 0 days 00:31:58\n"
     ]
    }
   ],
   "source": [
    "median_td = senegal_df.loc[ senegal_df['Q0__SurveyLengthTime__time'] >= pd.Timedelta(0), 'Q0__SurveyLengthTime__time' ].median()\n",
    "mask = senegal_df['Q0__SurveyLengthTime__time'] < pd.Timedelta(0)\n",
    "print(f\"Found {mask.sum()} negative Survey_Length(s), filling with median = {median_td}\")\n",
    "senegal_df.loc[mask, 'Q0__SurveyLengthTime__time'] = median_td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine survey analysis function by adding standard deviation markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "1c956e20-3ac3-4efe-ba2c-f74283e6da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def analyze_survey_length(df, column='Q0__SurveyLengthTime__time', bins=30, max_std=3):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of survey lengths in a DataFrame,\n",
    "    and overlay vertical lines at mean ± n * std for n = 1..max_std.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the survey length column.\n",
    "    column : str, default 'Survey_Length'\n",
    "        Name of the timedelta column to analyze.\n",
    "    bins : int, default 30\n",
    "        Number of histogram bins.\n",
    "    max_std : int, default 3\n",
    "        How many standard-deviation multiples to draw lines for.\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    - Histogram of survey lengths (HH:MM:SS) distribution with σ-lines.\n",
    "    - Printed mean and standard deviation of survey lengths.\n",
    "    - Returns a tuple (mean_timedelta, std_timedelta).\n",
    "    \"\"\"\n",
    "    # 1) Type check\n",
    "    if not pd.api.types.is_timedelta64_dtype(df[column]):\n",
    "        raise TypeError(f\"Column '{column}' must be timedelta64[ns] dtype\")\n",
    "\n",
    "    # 2) Compute statistics\n",
    "    mean_td = df[column].mean()\n",
    "    std_td  = df[column].std()\n",
    "\n",
    "    mean_sec = mean_td.total_seconds()\n",
    "    std_sec  = std_td.total_seconds()\n",
    "\n",
    "    # 3) Build histogram\n",
    "    secs = df[column].dt.total_seconds()\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    ax.hist(secs, bins=bins, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(\"Distribution of Survey Lengths\")\n",
    "    ax.set_xlabel(\"Survey Length (HH:MM:SS)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "    # Formatter: seconds → HH:MM:SS\n",
    "    def sec_to_hhmmss(x, pos):\n",
    "        h = int(x // 3600)\n",
    "        m = int((x % 3600) // 60)\n",
    "        s = int(x % 60)\n",
    "        return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(sec_to_hhmmss))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # 4) Overlay mean and std-bands\n",
    "    #    use different linestyles/colors for clarity\n",
    "    for n in range(0, max_std+1):\n",
    "        # skip n=0 since that’s the mean line (draw it separately for legend clarity)\n",
    "        if n == 0:\n",
    "            ax.axvline(mean_sec, color='black', linestyle='-', linewidth=2,\n",
    "                       label='Mean')\n",
    "        else:\n",
    "            for sign, label in [(+1, f'+{n}σ'), (-1, f'-{n}σ')]:\n",
    "                x = mean_sec + sign * n * std_sec\n",
    "                ax.axvline(x, linestyle='--' if n==1 else ':',\n",
    "                           linewidth=1.5 if n==1 else 1,\n",
    "                           label=label if sign>0 else None)\n",
    "    # Only one -σ label needed, so we skip labeling the negative side\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 5) Print out\n",
    "    mean_str = str(mean_td).split()[-1]\n",
    "    std_str  = str(std_td).split()[-1]\n",
    "    print(f\"Mean survey length: {mean_str}\")\n",
    "    print(f\"Std dev survey length: {std_str}\")\n",
    "\n",
    "    return mean_td, std_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "35407d79-a680-4d20-87d5-9eac98c0b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    print(\"SENEGAL DATA\")\n",
    "    analyze_survey_length(senegal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers defined as beyond 3 standard deviations, we swap outliers with median survey length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "128b58f0-db8e-40ac-8c5d-c05f42edb2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed 3 outlier survey lengths to median\n"
     ]
    }
   ],
   "source": [
    "threshold = senegal_df['Q0__SurveyLengthTime__time'].mean() + 2*senegal_df['Q0__SurveyLengthTime__time'].std()\n",
    "mask = senegal_df['Q0__SurveyLengthTime__time'] > threshold\n",
    "print(f\"Changed {mask.sum()} outlier survey lengths to median\")\n",
    "senegal_df.loc[mask, 'Q0__SurveyLengthTime__time'] = median_td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recheck survey length histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "934b4039-77d0-44df-9b08-c307f4f74e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    print(\"SENEGAL DATA\")\n",
    "    analyze_survey_length(senegal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ad0ff-3968-4fe5-9020-3af1540311f1",
   "metadata": {},
   "source": [
    "## Analyze Locational Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since added Survey_Length column, took out others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "ab8402b2-d4d7-4488-9b56-ba0a0137640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nepal_df = nepal_df.drop(['Q0__SurveyedEndTime__time'], axis=1)\n",
    "senegal_df = senegal_df.drop(['Q0__Surveyed_End_Date__time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing missing columns in the Senegal dataset's Location_... columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "30667ccb-75c1-435a-8d51-d3e38f7e0727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values in Q1__Location_Latitude: 335\n",
      "missing values in Latitude: 0\n",
      "missing values in Q1__Location_Longitude: 335\n",
      "missing values in Longitude: 0\n",
      "missing values in Q1__Location_Altitude: 335\n",
      "missing values in Altitude: 0\n",
      "missing values in Q1__Location_Accuracy: 335\n",
      "missing values in Accuracy: 0\n"
     ]
    }
   ],
   "source": [
    "for column in ['Latitude', 'Longitude', 'Altitude', 'Accuracy']:\n",
    "    print(f\"missing values in Q1__Location_{column}: {senegal_df[f'Q1__Location_{column}__continuous'].isna().sum()}\")\n",
    "    print(f\"missing values in {column}: {senegal_df[f'Q1__{column}__continuous'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Location_ columns from senegal data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "ccad853b-d0d9-410b-ab10-cd481d4f2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "senegal_df = senegal_df.drop(['Q1__Location_Latitude__continuous', 'Q1__Location_Longitude__continuous', 'Q1__Location_Altitude__continuous', 'Q1__Location_Accuracy__continuous'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are ok for nepal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "1bed6ab4-eb14-44bc-a6c9-dbeb62075545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values in Location_Latitude: 0\n",
      "missing values in Latitude: 0\n",
      "missing values in Location_Longitude: 0\n",
      "missing values in Longitude: 0\n",
      "missing values in Location_Altitude: 0\n",
      "missing values in Altitude: 0\n",
      "missing values in Location_Accuracy: 0\n",
      "missing values in Accuracy: 0\n"
     ]
    }
   ],
   "source": [
    "for column in ['Latitude', 'Longitude', 'Altitude', 'Accuracy']:\n",
    "    print(f\"missing values in Location_{column}: {nepal_df[f'Q1__Location_{column}__continuous'].isna().sum()}\")\n",
    "    print(f\"missing values in {column}: {nepal_df[f'Q1__{column}__continuous'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still removing from nepal Location_ columns for consistency between both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "d9249852-d6d5-4a72-bb03-8dbc1e438488",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepal_df = nepal_df.drop(['Q1__Location_Latitude__continuous', 'Q1__Location_Longitude__continuous', 'Q1__Location_Altitude__continuous', 'Q1__Location_Accuracy__continuous'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function to analyze locational columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "5749cede-e5f2-4f59-b52c-e4b8d010a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "def lat_lon_hillshade_map(df, zoom_start=11):\n",
    "    \"\"\"\n",
    "    Folium map with:\n",
    "      • Default OpenStreetMap layer\n",
    "      • ESRI World Hillshade (true terrain) layer\n",
    "      • MarkerCluster of your points with Altitude pop-ups\n",
    "      • LayerControl for toggling back and forth\n",
    "    \"\"\"\n",
    "    # 1) Prepare & center\n",
    "    df_map = df.dropna(subset=['Q1__Latitude__continuous','Q1__Longitude__continuous']).copy()\n",
    "    center = [df_map['Q1__Latitude__continuous'].mean(), df_map['Q1__Longitude__continuous'].mean()]\n",
    "\n",
    "    # 2) Build base map (OSM by default)\n",
    "    m = folium.Map(location=center, zoom_start=zoom_start)\n",
    "\n",
    "    # 3) Add ESRI World Hillshade as a second base layer\n",
    "    folium.TileLayer(\n",
    "        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/'\n",
    "              'Elevation/World_Hillshade/MapServer/tile/{z}/{y}/{x}',\n",
    "        attr='Tiles © Esri — Source: USGS',\n",
    "        name='Hillshade (ESRI)'\n",
    "    ).add_to(m)\n",
    "\n",
    "    # 4) Your markers (clustered)\n",
    "    mc = MarkerCluster(name='Points').add_to(m)\n",
    "    for idx, row in df_map.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row['Q1__Latitude__continuous'], row['Q1__Longitude__continuous']],\n",
    "            popup=(\n",
    "                f\"<b>Index:</b> {idx}<br>\"\n",
    "                f\"<b>Altitude:</b> {row.get('Q1__Altitude__continuous','N/A')} m\"\n",
    "            )\n",
    "        ).add_to(mc)\n",
    "\n",
    "    # 5) Toggle control\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze lat long data for nepal, both openstreetmap and hillshade for elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "1dcc78c5-1516-44ee-aaa6-72640660a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    nepal_map = lat_lon_hillshade_map(nepal_df)\n",
    "    nepal_map   # in Jupyter this will render with two base‐layers to switch between\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same for Senegal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "00523075-5b8e-4e65-8a44-754fd75e3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    print(\"SENEGAL DATA\")\n",
    "    senegal_map = lat_lon_hillshade_map(senegal_df)\n",
    "    senegal_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check against google if the altitude column is accurate given the lat lot coordinates, plot accuracy also to see if there is some connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "73fb5d68-2bbe-4b1b-b1b6-6c1c89070a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def plot_altitude_error(df, lat_col='Q1__Latitude__continuous', lon_col='Q1__Longitude__continuous', alt_col='Q1__Altitude__continuous', accuracy_col='Q1__Accuracy__continuous', api_url='https://api.open-elevation.com/api/v1/lookup', batch_size=100, bins=30):\n",
    "    '''\n",
    "    Fetches true elevations and plots a combined view showing:\n",
    "      - Histogram of altitude errors (recorded - true).\n",
    "      - Median reported accuracy for each error bin overlaid as a line.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with latitude, longitude, recorded altitude, and accuracy columns.\n",
    "    lat_col (str): Name of the latitude column.\n",
    "    lon_col (str): Name of the longitude column.\n",
    "    alt_col (str): Name of the recorded altitude column.\n",
    "    accuracy_col (str): Name of the accuracy column.\n",
    "    api_url (str): Elevation API endpoint.\n",
    "    batch_size (int): Number of locations per API request.\n",
    "    bins (int): Number of bins for error histogram and averaging.\n",
    "\n",
    "    Returns:\n",
    "    None. Displays a joint plot of error distribution and median accuracy per error bin.\n",
    "    '''\n",
    "    # Work on a copy\n",
    "    df = df.copy()\n",
    "    true_alts = []\n",
    "\n",
    "    # Batch request loop to fetch true elevations\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        locations = '|'.join(f\"{lat},{lon}\" for lat, lon in zip(batch[lat_col], batch[lon_col]))\n",
    "        resp = requests.get(api_url, params={'locations': locations})\n",
    "        resp.raise_for_status()\n",
    "        results = resp.json().get('results', [])\n",
    "        if len(results) != len(batch):\n",
    "            raise ValueError(f\"Expected {len(batch)} results, got {len(results)}\")\n",
    "        true_alts.extend(r['elevation'] for r in results)\n",
    "\n",
    "    # Compute errors and extract accuracy\n",
    "    recorded = df[alt_col].values\n",
    "    errors = recorded - np.array(true_alts)\n",
    "    accuracies = df[accuracy_col].values\n",
    "\n",
    "    # Prepare bins and compute median accuracy per bin\n",
    "    bin_edges = np.linspace(errors.min(), errors.max(), bins + 1)\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "    digitized = np.digitize(errors, bin_edges) - 1\n",
    "    median_acc = [np.median(accuracies[digitized == i]) if np.any(digitized == i) else np.nan for i in range(bins)]\n",
    "\n",
    "    # Create combined plot\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Histogram of errors\n",
    "    ax1.hist(errors, bins=bin_edges, alpha=0.6)\n",
    "    ax1.set_xlabel('Altitude Error (m)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.axvline(0, color='k', linestyle='--')\n",
    "\n",
    "\n",
    "    plt.title('Altitude Error Distribution with Median Accuracy per Error Bin')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "0e589b22-d596-4723-9eb0-3ba37e153bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    plot_altitude_error(nepal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "de92c5e5-cc9e-43fd-a2a7-4d9a17a8ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    plot_altitude_error(senegal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like gaussian noise error, just keep these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05661c",
   "metadata": {},
   "source": [
    "## Add resilience index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "4beab0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_abs_features(\n",
    "    df: pd.DataFrame,\n",
    "    lat_col: str = \"lat\",\n",
    "    lon_col: str = \"lon\",\n",
    "    water_thresh: float = 100,   # meters\n",
    "    toilet_thresh: float = 50,    # meters\n",
    "    elec_thresh: float = 100      # meters\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enrich any DataFrame with (lat,lon) cols by adding:\n",
    "      • abs_water_access  (0/1)\n",
    "      • abs_toilet        (0/1)\n",
    "      • abs_electricity   (0/1)\n",
    "    plus these distance columns (in meters):\n",
    "      dist_water_source, dist_toilet, dist_power_line,\n",
    "      dist_primary_school, dist_health_facility,\n",
    "      dist_livestock_market, dist_agri_market,\n",
    "      dist_public_transport\n",
    "    \"\"\"\n",
    "    # 1. Rename & build GeoDataFrame in EPSG:4326 → project to EPSG:3857 for meters\n",
    "    df2 = df.rename(columns={lat_col: \"lat\", lon_col: \"lon\"}).copy()\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df2,\n",
    "        geometry=gpd.points_from_xy(df2.lon, df2.lat),\n",
    "        crs=\"EPSG:4326\"\n",
    "    ).to_crs(epsg=3857)\n",
    "\n",
    "    def add_osm_distance(gdf, tags: dict, col: str):\n",
    "        # compute lat/lon bbox from projected gdf\n",
    "        north, south, east, west = gdf.to_crs(epsg=4326).total_bounds[[3,1,2,0]]\n",
    "        pad = 0.02  # degrees\n",
    "        north += pad; south -= pad; east += pad; west -= pad\n",
    "        bbox = (west, south, east, north)  # (left, bottom, right, top)\n",
    "\n",
    "        # fetch POIs within bbox; signature is features_from_bbox(bbox, tags) :contentReference[oaicite:1]{index=1}\n",
    "        pois = ox.features_from_bbox(bbox, tags)\n",
    "\n",
    "        if pois.empty:\n",
    "            gdf[col] = np.nan\n",
    "        else:\n",
    "            # merge all geometries to speed up distance queries\n",
    "            geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
    "            gdf[col] = gdf.geometry.apply(lambda p: p.distance(geom_union))\n",
    "        return gdf\n",
    "\n",
    "    # 2. Compute each service distance\n",
    "    gdf = add_osm_distance(gdf, {\"amenity\":\"drinking_water\"},     \"dist_water_source\")\n",
    "    gdf = add_osm_distance(gdf, {\"amenity\":\"toilets\"},            \"dist_toilet\")\n",
    "    gdf = add_osm_distance(gdf, {\"power\":\"line\"},                 \"dist_power_line\")\n",
    "    gdf = add_osm_distance(gdf, {\"amenity\":\"school\"},             \"dist_primary_school\")\n",
    "    gdf = add_osm_distance(gdf, {\"amenity\":[\"hospital\",\"clinic\"]},\"dist_health_facility\")\n",
    "    gdf = add_osm_distance(gdf, {\"amenity\":\"marketplace\"},        \"dist_livestock_market\")\n",
    "    gdf = add_osm_distance(gdf, {\"shop\":\"greengrocer\"},           \"dist_agri_market\")\n",
    "    # public transport = nearest of bus_station or bus_stop\n",
    "    gdf = add_osm_distance(gdf, {\"amenity\":\"bus_station\"},        \"dist_bus_station\")\n",
    "    gdf = add_osm_distance(gdf, {\"highway\":\"bus_stop\"},           \"dist_bus_stop\")\n",
    "    gdf[\"dist_public_transport\"] = gdf[[\"dist_bus_station\",\"dist_bus_stop\"]].min(axis=1)\n",
    "\n",
    "    # 4. Return original + ABS columns\n",
    "    cols = [\n",
    "      \"dist_water_source\",\"dist_toilet\",\"dist_power_line\",\n",
    "      \"dist_primary_school\",\"dist_health_facility\",\n",
    "      \"dist_livestock_market\",\"dist_agri_market\",\"dist_public_transport\"\n",
    "    ]\n",
    "    df2 = df.rename(columns={\"lat\": lat_col, \"lon\": lon_col}).copy()\n",
    "    return pd.concat([df2.reset_index(drop=True), gdf[cols].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "e171476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2725292146.py:42: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  geom_union = pois.to_crs(epsg=3857).geometry.unary_union\n"
     ]
    }
   ],
   "source": [
    "nepal_df = add_abs_features(\n",
    "    nepal_df,\n",
    "    lat_col=\"Q1__Latitude__continuous\",\n",
    "    lon_col=\"Q1__Longitude__continuous\"\n",
    ")\n",
    "\n",
    "senegal_df = add_abs_features(\n",
    "    senegal_df,\n",
    "    lat_col=\"Q1__Latitude__continuous\",\n",
    "    lon_col=\"Q1__Longitude__continuous\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "2c068a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Q0__sustainable_livelihood_score__continuous\n",
      "0                                      0.757433\n",
      "1                                      0.642556\n",
      "2                                      1.087853\n",
      "3                                      0.801880\n",
      "4                                     -0.261796\n",
      "   Q0__sustainable_livelihood_score__continuous\n",
      "0                                      0.420186\n",
      "1                                      0.680015\n",
      "2                                      0.011791\n",
      "3                                      0.278026\n",
      "4                                     -0.860718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def compute_sustainable_livelihood_score(\n",
    "    df: pd.DataFrame,\n",
    "    country: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute a 0–1 'sustainable_livelihood_score' as a formative composite\n",
    "    across five livelihood domains, using PCA(1+2) per domain where needed.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    country = country.lower()\n",
    "    \n",
    "    # ── 1. Domain → feature lists ──────────────────────────────────────────\n",
    "    if country == \"nepal\":\n",
    "        domain_features = {\n",
    "            \"natural\": [\n",
    "                \"Q50__How_much_land_that_is_yours_do_you_cultivate_bigha__continuous\",\n",
    "                \"Q51__How_much_land_that_is_rented_or_leased_do_you_cultivate_bigha__continuous\",\n",
    "                \"Q52__On_how_much_land_do_you_grow_vegetables_bigha__continuous\",\n",
    "                \"Q62__How_much_VEGETABLES_do_you_harvest_per_year_from_this_plot_kilograms__continuous\",\n",
    "                \"Q0__TOTAL_AREA__continuous\"\n",
    "            ],\n",
    "            \"physical\": [\n",
    "                \"Q55__For_Vegetables_do_you_use_improved_and_or_variety_seeds_yes__binary__1\",\n",
    "                \"Q57__If_you_self_prepare_seedlings_how_Nursery__binary__1\",\n",
    "                \"Q60__do_you_use_pesticides_or_herbicides_on_this_plot_Yes__binary__1\",\n",
    "                \"Q78__How_many_years_have_you_been_using_drip_irrigation_if_no_zero__continuous\",\n",
    "                \"dist_water_source\",\"dist_toilet\",\"dist_power_line\",\n",
    "                \"dist_primary_school\",\"dist_health_facility\",\n",
    "                \"dist_livestock_market\",\"dist_agri_market\",\"dist_public_transport\"\n",
    "            ],\n",
    "            \"financial\": [\n",
    "                \"Q108__What_is_your_households_yearly_income_from_agriculture_NPR__continuous\",\n",
    "                \"Q109__What_is_your_households_yearly_income_overall_including_agriculture_NPR__continuous\",\n",
    "                \"Q110__Do_you_currently_have_a_loan_if_no_zero_if_yes_amount_of_money_loaned_NPR__continuous\",\n",
    "                \"Q70__in_the_past_12_months_did_you_receive_any_info_from_anyone_on_agriculture__binary__1\"\n",
    "            ],\n",
    "            \"human\": [\n",
    "                \"Q101__how_many_people_live_in_this_household__continuous\",\n",
    "                \"Q5__AgeYears__continuous\",\n",
    "                \"Q106__Education_level_of_this_person_that_is_interviewed_years_of_formal_education__continuous\",\n",
    "                \"Q107__Education_level_of_your_wife_husband_How_many_years_of_formal_education__continuous\"\n",
    "            ],\n",
    "            \"social\": [\n",
    "                \"Q0__hope_total__continuous\",\n",
    "                \"Q0__self_control_score__continuous\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    elif country == \"senegal\":\n",
    "        domain_features = {\n",
    "            \"natural\": [\n",
    "                \"Q60__Land_owned_cultivated_ha__continuous\",\n",
    "                \"Q61__Land_rented_cultivated_ha__continuous\",\n",
    "                \"Q62__Land_grow_vegetables_ha__continuous\",\n",
    "                \"Q71__VEG_harvest_per_year_kg__continuous\"\n",
    "            ],\n",
    "            \"physical\": [\n",
    "                \"Q69__Use_pesticide_or_herbicide__binary__1\",\n",
    "                \"Q84__Years_using_drip_irrigation__continuous\",\n",
    "                \"Q76__Received_agri_info_last_12m__binary__1\",\n",
    "                \"dist_water_source\",\"dist_toilet\",\"dist_power_line\",\n",
    "                \"dist_primary_school\",\"dist_health_facility\",\n",
    "                \"dist_livestock_market\",\"dist_agri_market\",\"dist_public_transport\"\n",
    "            ],\n",
    "            \"financial\": [\n",
    "                \"Q90__Yearly_income_agriculture_XOF__continuous\",\n",
    "                \"Q91__Yearly_income_overall_XOF__continuous\",\n",
    "                \"Q92__Current_loan_amount_XOF__continuous\"\n",
    "            ],\n",
    "            \"human\": [\n",
    "                \"Q87__Household_size__continuous\",\n",
    "                \"Q5__Age__continuous\",\n",
    "                \"Q0__Education_years__continuous\"\n",
    "            ],\n",
    "            \"social\": [\n",
    "                \"Q0__Hope_total__continuous\",\n",
    "                \"Q93__Trust_most_people__ordinal\"\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"country must be 'nepal' or 'senegal'\")\n",
    "\n",
    "    # ── 2. Summarize each domain with PCA(1) or PCA(1+2) ────────────────────\n",
    "    domain_evr    = {}\n",
    "    domain_scores = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for domain, feats in domain_features.items():\n",
    "        # a) subset, fill, standardize\n",
    "        X  = df[feats].copy().fillna(df[feats].mean())\n",
    "        Xs = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # b) fit two PCs\n",
    "        pca      = PCA(n_components=2, random_state=0).fit(Xs)\n",
    "        evr1,evr2 = pca.explained_variance_ratio_\n",
    "        comp1,comp2 = pca.transform(Xs).T\n",
    "\n",
    "        # c) if PC1 <50% capture, fold in PC2\n",
    "        if evr1 < 0.50:\n",
    "            w1 = evr1 / (evr1 + evr2)\n",
    "            w2 = evr2 / (evr1 + evr2)\n",
    "            score = w1 * comp1 + w2 * comp2\n",
    "            domain_evr[domain] = evr1 + evr2\n",
    "        else:\n",
    "            score = comp1\n",
    "            domain_evr[domain] = evr1\n",
    "\n",
    "        domain_scores[f\"{domain}_score\"] = score\n",
    "\n",
    "    # ── 3. Composite: variance‐weighted sum of domain scores ────────────────\n",
    "    total_evr = sum(domain_evr.values())\n",
    "    weights   = {d: evr / total_evr for d, evr in domain_evr.items()}\n",
    "\n",
    "    # build composite score\n",
    "    composite = sum(domain_scores[f\"{d}_score\"] * w for d,w in weights.items())\n",
    "    df[\"Q0__sustainable_livelihood_score__continuous\"] = composite\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ── Usage ───────────────────────────────────────────────────────────────\n",
    "nepal_df   = compute_sustainable_livelihood_score(nepal_df,   country=\"nepal\")\n",
    "senegal_df = compute_sustainable_livelihood_score(senegal_df, country=\"senegal\")\n",
    "\n",
    "print(nepal_df[[\"Q0__sustainable_livelihood_score__continuous\"]].head())\n",
    "print(senegal_df[[\"Q0__sustainable_livelihood_score__continuous\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce3ad322ee23a",
   "metadata": {},
   "source": [
    "## Analyze All Other Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to plot the marginal distributions of the remaining features, bar plots used for categorical features and histograms for numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "0e305327-abe5-4162-a3d1-a9576f6bc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def plot_marginals(df: pd.DataFrame):\n",
    "    # Group columns by question\n",
    "    groups = defaultdict(list)\n",
    "    for col in df.columns:\n",
    "        meta = parse_feature_metadata(col)\n",
    "        if meta:\n",
    "            groups[meta[\"qid\"]].append(col)\n",
    "\n",
    "    for qid, cols in groups.items():\n",
    "        meta0 = parse_feature_metadata(cols[0])\n",
    "        ftype = meta0[\"type\"]\n",
    "        feat = meta0[\"name\"].replace('_', ' ')\n",
    "\n",
    "        plt.figure()\n",
    "        if ftype == \"binary\":\n",
    "            # ---- single‐select (<=2 columns) ----\n",
    "            if len(cols) <= 2:\n",
    "                # pick the “yes” column: if only one, use that; if two, look for '-1'\n",
    "                if len(cols) == 1:\n",
    "                    yes_col = cols[0]\n",
    "                else:\n",
    "                    yes_col = next(c for c in cols if c.endswith('-1'))\n",
    "                ser = df[yes_col].fillna(0).astype(int)\n",
    "                ser.value_counts().sort_index().plot(kind=\"bar\", rot=0)\n",
    "                plt.title(f\"{qid} {feat} (binary yes/no)\")\n",
    "                plt.xlabel(feat)\n",
    "                plt.ylabel(\"Count\")\n",
    "\n",
    "            # ---- multi‐select (>2 columns) ----\n",
    "            else:\n",
    "                counts = df[cols].fillna(0).astype(int).sum(axis=0)\n",
    "                labels = [parse_feature_metadata(c)[\"name\"].replace('_',' ')\n",
    "                          for c in cols]\n",
    "                pd.Series(counts.values, index=labels)\\\n",
    "                  .sort_values(ascending=False)\\\n",
    "                  .plot(kind=\"bar\", rot=45)\n",
    "                plt.title(f\"{qid} {feat} (multi-select)\")\n",
    "                plt.xlabel(feat)\n",
    "                plt.ylabel(\"Count\")\n",
    "\n",
    "        else:\n",
    "            # continuous/ordinal/nominal\n",
    "            ser = df[cols[0]]\n",
    "            if pd.api.types.is_numeric_dtype(ser):\n",
    "                plt.hist(ser.dropna(), bins='auto')\n",
    "                plt.title(f\"{qid} {feat} ({ftype})\\n\"\n",
    "                          f\"mean={ser.mean():.2f}, std={ser.std():.2f}\")\n",
    "            else:\n",
    "                ser.value_counts().sort_index().plot(kind=\"bar\", rot=0)\n",
    "                plt.title(f\"{qid} {feat} ({ftype})\")\n",
    "                plt.xlabel(feat)\n",
    "                plt.ylabel(\"Count\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "634d73ef-bc85-4543-bc47-39f615963dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    plot_marginals(nepal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "1eeca221-d4d4-4f6d-bb96-655da6ff36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    plot_marginals(senegal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdfc431",
   "metadata": {},
   "source": [
    "# Continuous & Discrete Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "9e8fb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping non Q#... columns\n",
    "nepal_df = drop_non_relevant_columns(nepal_df)\n",
    "senegal_df = drop_non_relevant_columns(senegal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "5ba05ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cat_cols_nepal = []\n",
    "non_cat_cols_senegal = []\n",
    "for col in nepal_df.columns:\n",
    "    meta_type = parse_feature_metadata(col)['type']\n",
    "    if meta_type == \"continuous\":\n",
    "        non_cat_cols_nepal.append(col)\n",
    "\n",
    "for col in senegal_df.columns:\n",
    "\n",
    "    meta_type = parse_feature_metadata(col)['type']\n",
    "    \n",
    "    if meta_type == \"continuous\":\n",
    "        non_cat_cols_senegal.append(col)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "b65d3ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per non-categorical column in nepal:\n",
      "Q1__Latitude__continuous                                                                           0\n",
      "Q1__Longitude__continuous                                                                          0\n",
      "Q1__Altitude__continuous                                                                           0\n",
      "Q1__Accuracy__continuous                                                                           0\n",
      "Q5__AgeYears__continuous                                                                           0\n",
      "Q50__How_much_land_that_is_yours_do_you_cultivate_bigha__continuous                                0\n",
      "Q51__How_much_land_that_is_rented_or_leased_do_you_cultivate_bigha__continuous                     0\n",
      "Q52__On_how_much_land_do_you_grow_vegetables_bigha__continuous                                     1\n",
      "Q62__How_much_VEGETABLES_do_you_harvest_per_year_from_this_plot_kilograms__continuous              0\n",
      "Q78__How_many_years_have_you_been_using_drip_irrigation_if_no_zero__continuous                     1\n",
      "Q101__how_many_people_live_in_this_household__continuous                                           0\n",
      "Q102__How_many_children_do_you_have__continuous                                                   17\n",
      "Q103__How_many_children_do_you_plan_to_have_in_your_whole_live__continuous                        17\n",
      "Q106__Education_level_of_this_person_that_is_interviewed_years_of_formal_education__continuous     1\n",
      "Q107__Education_level_of_your_wife_husband_How_many_years_of_formal_education__continuous          0\n",
      "Q108__What_is_your_households_yearly_income_from_agriculture_NPR__continuous                       0\n",
      "Q109__What_is_your_households_yearly_income_overall_including_agriculture_NPR__continuous          1\n",
      "Q110__Do_you_currently_have_a_loan_if_no_zero_if_yes_amount_of_money_loaned_NPR__continuous        0\n",
      "Q0__hope_total__continuous                                                                         0\n",
      "Q0__positive_total__continuous                                                                     0\n",
      "Q0__negative_total__continuous                                                                     0\n",
      "Q0__Positive_Negative_Score__continuous                                                            0\n",
      "Q0__Distance__continuous                                                                           0\n",
      "Q0__TOTAL_AREA__continuous                                                                         0\n",
      "Q0__self_control_score__continuous                                                                 0\n",
      "Q0__target1_yearly_income_from_agr_per_land_SQM__continuous                                        0\n",
      "Q0__target2_yearly_income_from_agr_USD__continuous                                                 0\n",
      "Q0__target3_veg_per_area__continuous                                                               1\n",
      "Q0__sustainable_livelihood_score__continuous                                                       0\n",
      "dtype: int64\n",
      "Missing values per non-categorical column in senegal:\n",
      "Q1__Latitude__continuous                                       0\n",
      "Q1__Longitude__continuous                                      0\n",
      "Q1__Altitude__continuous                                       0\n",
      "Q1__Accuracy__continuous                                       0\n",
      "Q5__Age__continuous                                            1\n",
      "Q0__Hope_total__continuous                                     0\n",
      "Q0__Average_CS__continuous                                     0\n",
      "Q60__Land_owned_cultivated_ha__continuous                      0\n",
      "Q61__Land_rented_cultivated_ha__continuous                     0\n",
      "Q62__Land_grow_vegetables_ha__continuous                       0\n",
      "Q71__VEG_harvest_per_year_kg__continuous                       0\n",
      "Q84__Years_using_drip_irrigation__continuous                   0\n",
      "Q87__Household_size__continuous                                3\n",
      "Q0__Education_years__continuous                                0\n",
      "Q90__Yearly_income_agriculture_XOF__continuous                 0\n",
      "Q91__Yearly_income_overall_XOF__continuous                     0\n",
      "Q92__Current_loan_amount_XOF__continuous                       0\n",
      "Q0__Distance_Thies_KM__continuous                              0\n",
      "Q0__Distance_Dakar_KM__continuous                              0\n",
      "Q0__Age_Education_interaction__continuous                      1\n",
      "Q0__target1_yearly_income_from_agr_per_land_SQM__continuous    0\n",
      "Q0__target2_yearly_income_from_agr_USD__continuous             0\n",
      "Q0__target3_veg_per_area__continuous                           0\n",
      "Q0__sustainable_livelihood_score__continuous                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_counts_nepal = nepal_df[non_cat_cols_nepal].isnull().sum()\n",
    "print(\"Missing values per non-categorical column in nepal:\")\n",
    "print(missing_counts_nepal)\n",
    "\n",
    "missing_counts_senegal = senegal_df[non_cat_cols_senegal].isnull().sum()\n",
    "print(\"Missing values per non-categorical column in senegal:\")\n",
    "print(missing_counts_senegal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if missingness of How_many_children_do_you... columns in nepal are random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "9d76264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "children_cols = ['Q102__How_many_children_do_you_have__continuous', 'Q103__How_many_children_do_you_plan_to_have_in_your_whole_live__continuous']\n",
    "y_col = 'Q0__target2_yearly_income_from_agr_USD__continuous'\n",
    "\n",
    "if PLOT_GRAPHS:\n",
    "    for col in children_cols:\n",
    "\n",
    "        mask_missing = nepal_df[col].isnull().values\n",
    "\n",
    "        # Choose colors for each point\n",
    "        colors = np.where(mask_missing, 'red', 'blue')\n",
    "\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.scatter(nepal_df.index, nepal_df[y_col], c=colors, alpha=0.7)\n",
    "        plt.xlabel(\"Index\")\n",
    "        plt.ylabel(\"Yearly Income from Agriculture (USD)\")\n",
    "        plt.title(\"Yearly Income from Agriculture (USD) vs. index\\n\\nRed = 'how many children' feature was missing\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missingness is uniformly spread throughout. We remove the columns because our coordinator\n",
    "said we should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "3a8e244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepal_df = nepal_df.drop(columns=children_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "847ae26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in children_cols:\n",
    "    non_cat_cols_nepal.remove(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0a8f4",
   "metadata": {},
   "source": [
    "For the rest, fill missing values with median since very small amount of them and don't want to lose farmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "323764d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepal_df[non_cat_cols_nepal] = nepal_df[non_cat_cols_nepal].fillna(nepal_df[non_cat_cols_nepal].median())\n",
    "senegal_df[non_cat_cols_senegal] = senegal_df[non_cat_cols_senegal].fillna(senegal_df[non_cat_cols_senegal].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recheck missing values in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "d767acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per non-categorical column in nepal:\n",
      "Q1__Latitude__continuous                                                                          0\n",
      "Q1__Longitude__continuous                                                                         0\n",
      "Q1__Altitude__continuous                                                                          0\n",
      "Q1__Accuracy__continuous                                                                          0\n",
      "Q5__AgeYears__continuous                                                                          0\n",
      "Q50__How_much_land_that_is_yours_do_you_cultivate_bigha__continuous                               0\n",
      "Q51__How_much_land_that_is_rented_or_leased_do_you_cultivate_bigha__continuous                    0\n",
      "Q52__On_how_much_land_do_you_grow_vegetables_bigha__continuous                                    0\n",
      "Q62__How_much_VEGETABLES_do_you_harvest_per_year_from_this_plot_kilograms__continuous             0\n",
      "Q78__How_many_years_have_you_been_using_drip_irrigation_if_no_zero__continuous                    0\n",
      "Q101__how_many_people_live_in_this_household__continuous                                          0\n",
      "Q106__Education_level_of_this_person_that_is_interviewed_years_of_formal_education__continuous    0\n",
      "Q107__Education_level_of_your_wife_husband_How_many_years_of_formal_education__continuous         0\n",
      "Q108__What_is_your_households_yearly_income_from_agriculture_NPR__continuous                      0\n",
      "Q109__What_is_your_households_yearly_income_overall_including_agriculture_NPR__continuous         0\n",
      "Q110__Do_you_currently_have_a_loan_if_no_zero_if_yes_amount_of_money_loaned_NPR__continuous       0\n",
      "Q0__hope_total__continuous                                                                        0\n",
      "Q0__positive_total__continuous                                                                    0\n",
      "Q0__negative_total__continuous                                                                    0\n",
      "Q0__Positive_Negative_Score__continuous                                                           0\n",
      "Q0__Distance__continuous                                                                          0\n",
      "Q0__TOTAL_AREA__continuous                                                                        0\n",
      "Q0__self_control_score__continuous                                                                0\n",
      "Q0__target1_yearly_income_from_agr_per_land_SQM__continuous                                       0\n",
      "Q0__target2_yearly_income_from_agr_USD__continuous                                                0\n",
      "Q0__target3_veg_per_area__continuous                                                              0\n",
      "Q0__sustainable_livelihood_score__continuous                                                      0\n",
      "dtype: int64\n",
      "Missing values per non-categorical column in senegal:\n",
      "Q1__Latitude__continuous                                       0\n",
      "Q1__Longitude__continuous                                      0\n",
      "Q1__Altitude__continuous                                       0\n",
      "Q1__Accuracy__continuous                                       0\n",
      "Q5__Age__continuous                                            0\n",
      "Q0__Hope_total__continuous                                     0\n",
      "Q0__Average_CS__continuous                                     0\n",
      "Q60__Land_owned_cultivated_ha__continuous                      0\n",
      "Q61__Land_rented_cultivated_ha__continuous                     0\n",
      "Q62__Land_grow_vegetables_ha__continuous                       0\n",
      "Q71__VEG_harvest_per_year_kg__continuous                       0\n",
      "Q84__Years_using_drip_irrigation__continuous                   0\n",
      "Q87__Household_size__continuous                                0\n",
      "Q0__Education_years__continuous                                0\n",
      "Q90__Yearly_income_agriculture_XOF__continuous                 0\n",
      "Q91__Yearly_income_overall_XOF__continuous                     0\n",
      "Q92__Current_loan_amount_XOF__continuous                       0\n",
      "Q0__Distance_Thies_KM__continuous                              0\n",
      "Q0__Distance_Dakar_KM__continuous                              0\n",
      "Q0__Age_Education_interaction__continuous                      0\n",
      "Q0__target1_yearly_income_from_agr_per_land_SQM__continuous    0\n",
      "Q0__target2_yearly_income_from_agr_USD__continuous             0\n",
      "Q0__target3_veg_per_area__continuous                           0\n",
      "Q0__sustainable_livelihood_score__continuous                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many missing values per column\n",
    "missing_counts_nepal = nepal_df[non_cat_cols_nepal].isnull().sum()\n",
    "print(\"Missing values per non-categorical column in nepal:\")\n",
    "print(missing_counts_nepal)\n",
    "\n",
    "missing_counts_senegal = senegal_df[non_cat_cols_senegal].isnull().sum()\n",
    "print(\"Missing values per non-categorical column in senegal:\")\n",
    "print(missing_counts_senegal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173cd96",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check skew and kurtosis of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "72e40ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For nepal dataset:\n",
      "                                                     skewness    kurtosis\n",
      "Q1__Latitude__continuous                             2.501469   11.458427\n",
      "Q1__Longitude__continuous                           -2.078695    3.327960\n",
      "Q1__Altitude__continuous                             7.738261   61.181298\n",
      "Q1__Accuracy__continuous                             1.245955    1.722112\n",
      "Q5__AgeYears__continuous                             0.011752   -0.698653\n",
      "Q50__How_much_land_that_is_yours_do_you_cultiva...   0.380098   -0.503872\n",
      "Q51__How_much_land_that_is_rented_or_leased_do_...   2.428187    7.002975\n",
      "Q52__On_how_much_land_do_you_grow_vegetables_bi...   1.379596    1.564302\n",
      "Q62__How_much_VEGETABLES_do_you_harvest_per_yea...   7.498011   80.246841\n",
      "Q78__How_many_years_have_you_been_using_drip_ir...  13.138456  180.751947\n",
      "Q101__how_many_people_live_in_this_household__c...   1.779578    7.940154\n",
      "Q106__Education_level_of_this_person_that_is_in...  -0.183514    0.424381\n",
      "Q107__Education_level_of_your_wife_husband_How_...  -1.168109    0.796278\n",
      "Q108__What_is_your_households_yearly_income_fro...  14.294988  221.703194\n",
      "Q109__What_is_your_households_yearly_income_ove...   3.708312   34.412789\n",
      "Q110__Do_you_currently_have_a_loan_if_no_zero_i...   1.007137    0.722186\n",
      "Q0__hope_total__continuous                          -0.068428   -0.247737\n",
      "Q0__positive_total__continuous                      -0.995703    1.178711\n",
      "Q0__negative_total__continuous                       1.245883    1.792229\n",
      "Q0__Positive_Negative_Score__continuous             -0.139433    0.386755\n",
      "Q0__Distance__continuous                             2.168921    6.756909\n",
      "Q0__TOTAL_AREA__continuous                           0.814573    0.920237\n",
      "Q0__self_control_score__continuous                  -0.108054   -0.678342\n",
      "Q0__target1_yearly_income_from_agr_per_land_SQM...  11.195837  155.999342\n",
      "Q0__target2_yearly_income_from_agr_USD__continuous  14.294988  221.703194\n",
      "Q0__target3_veg_per_area__continuous                 3.051733   16.057869\n",
      "Q0__sustainable_livelihood_score__continuous         0.082709    1.480613\n"
     ]
    }
   ],
   "source": [
    "def print_per_col_skew_and_kurtosis(df, cols):\n",
    "    desc = pd.DataFrame(index=cols, columns=['skewness','kurtosis'])\n",
    "    desc['skewness'] = df[cols].skew()\n",
    "    desc['kurtosis'] = df[cols].kurtosis()\n",
    "    print(desc)\n",
    "\n",
    "print(\"For nepal dataset:\")\n",
    "print_per_col_skew_and_kurtosis(nepal_df, non_cat_cols_nepal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "f9e19821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For senegal dataset:\n",
      "                                                     skewness    kurtosis\n",
      "Q1__Latitude__continuous                             0.651947   -1.027130\n",
      "Q1__Longitude__continuous                            0.434510   -1.374106\n",
      "Q1__Altitude__continuous                            -0.027704    1.898947\n",
      "Q1__Accuracy__continuous                             2.523551    6.847364\n",
      "Q5__Age__continuous                                  0.067253   -0.843279\n",
      "Q0__Hope_total__continuous                           0.911953    1.005143\n",
      "Q0__Average_CS__continuous                           0.943979    0.344805\n",
      "Q60__Land_owned_cultivated_ha__continuous            0.261807   -1.177306\n",
      "Q61__Land_rented_cultivated_ha__continuous           4.403219   20.345663\n",
      "Q62__Land_grow_vegetables_ha__continuous             0.228387   -1.165957\n",
      "Q71__VEG_harvest_per_year_kg__continuous             2.712008   10.480210\n",
      "Q84__Years_using_drip_irrigation__continuous         2.467766    5.748366\n",
      "Q87__Household_size__continuous                      0.841336    1.153271\n",
      "Q0__Education_years__continuous                      1.471622    1.029800\n",
      "Q90__Yearly_income_agriculture_XOF__continuous      10.905860  157.091244\n",
      "Q91__Yearly_income_overall_XOF__continuous           1.020673    0.581433\n",
      "Q92__Current_loan_amount_XOF__continuous             5.617264   38.867939\n",
      "Q0__Distance_Thies_KM__continuous                   -0.382546    0.228726\n",
      "Q0__Distance_Dakar_KM__continuous                    0.536118   -1.229064\n",
      "Q0__Age_Education_interaction__continuous            0.104445    0.590217\n",
      "Q0__target1_yearly_income_from_agr_per_land_SQM...   3.680180   17.212542\n",
      "Q0__target2_yearly_income_from_agr_USD__continuous  10.905860  157.091244\n",
      "Q0__target3_veg_per_area__continuous                 5.179652   34.089035\n",
      "Q0__sustainable_livelihood_score__continuous         0.972576    1.983747\n"
     ]
    }
   ],
   "source": [
    "print(\"For senegal dataset:\")\n",
    "print_per_col_skew_and_kurtosis(senegal_df, non_cat_cols_senegal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of features have very long and heavy tails, would like also a visual understanding, we plot qq plots aswell for the non-categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "5c3d88e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nepal qq plots\n"
     ]
    }
   ],
   "source": [
    "# Get QQ plots\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "print(\"nepal qq plots\")\n",
    "if PLOT_GRAPHS:\n",
    "    for col in non_cat_cols_nepal:\n",
    "        plt.figure()\n",
    "        stats.probplot(nepal_df[col].dropna(), dist=\"norm\", plot=plt)\n",
    "        plt.title(f\"Q–Q plot for {col}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "1fcf34ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senegal qq plots\n"
     ]
    }
   ],
   "source": [
    "print(\"senegal qq plots\")\n",
    "if PLOT_GRAPHS:\n",
    "    for col in non_cat_cols_senegal:\n",
    "        plt.figure()\n",
    "        stats.probplot(senegal_df[col].dropna(), dist=\"norm\", plot=plt)\n",
    "        plt.title(f\"Q–Q plot for {col}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very assymetric and kurtosis high, would like to classify outliers in a robust manner, taking into account the shape of the empirical distribution, we will use robust z scores calculated using the Qn scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "055fe2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels import robust\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "def robust_z_scores(df, cols):\n",
    "\n",
    "    outlier_counts = {}\n",
    "    outlier_indices = {}\n",
    "    robust_z_scores = {}\n",
    "\n",
    "    for col in cols:\n",
    "        # 1. Grab the non-null values as a 1D NumPy array\n",
    "        data = df[col].dropna().values\n",
    "        \n",
    "        # 2. Compute Qn scale\n",
    "        qn = robust.scale.qn_scale(data)\n",
    "\n",
    "        # 3. Compute the column’s median\n",
    "        med = np.median(data)\n",
    "\n",
    "        # 4. Compute “robust z‐scores” relative to Qn\n",
    "        #    (Note: unlike classical z, this is robust to heavy tails & skew)\n",
    "        robust_z = (data - med) / qn\n",
    "        robust_z_scores[col] = robust_z\n",
    "        \n",
    "        # 5. Flag outliers\n",
    "        mask = np.abs(robust_z) > threshold\n",
    "        \n",
    "        # 6. Store counts and (optionally) original DataFrame indices\n",
    "        outlier_counts[col] = int(mask.sum())\n",
    "        # to get the original df indices:\n",
    "        outlier_indices[col] = df[col].dropna().index[mask].tolist()\n",
    "\n",
    "    # Convert to a nice summary DataFrame\n",
    "    summary = pd.DataFrame.from_dict({\n",
    "        'n_outliers': outlier_counts,\n",
    "        'pct_outliers': {c: outlier_counts[c] / df[c].count() * 100 \n",
    "                        for c in cols}\n",
    "    }).T\n",
    "\n",
    "    print(\"Outliers per column (using Qn):\")\n",
    "    print(summary)\n",
    "\n",
    "    return outlier_indices, robust_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "8d59488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied robust z-score outlier flagging to nepal:\n",
      "Outliers per column (using Qn):\n",
      "              Q1__Latitude__continuous  Q1__Longitude__continuous  \\\n",
      "n_outliers                   43.000000                  48.000000   \n",
      "pct_outliers                 16.044776                  17.910448   \n",
      "\n",
      "              Q1__Altitude__continuous  Q1__Accuracy__continuous  \\\n",
      "n_outliers                    9.000000                 11.000000   \n",
      "pct_outliers                  3.358209                  4.104478   \n",
      "\n",
      "              Q5__AgeYears__continuous  \\\n",
      "n_outliers                         0.0   \n",
      "pct_outliers                       0.0   \n",
      "\n",
      "              Q50__How_much_land_that_is_yours_do_you_cultivate_bigha__continuous  \\\n",
      "n_outliers                                           155.000000                     \n",
      "pct_outliers                                          57.835821                     \n",
      "\n",
      "              Q51__How_much_land_that_is_rented_or_leased_do_you_cultivate_bigha__continuous  \\\n",
      "n_outliers                                            50.000000                                \n",
      "pct_outliers                                          18.656716                                \n",
      "\n",
      "              Q52__On_how_much_land_do_you_grow_vegetables_bigha__continuous  \\\n",
      "n_outliers                                            104.00000                \n",
      "pct_outliers                                           38.80597                \n",
      "\n",
      "              Q62__How_much_VEGETABLES_do_you_harvest_per_year_from_this_plot_kilograms__continuous  \\\n",
      "n_outliers                                            17.000000                                       \n",
      "pct_outliers                                           6.343284                                       \n",
      "\n",
      "              Q78__How_many_years_have_you_been_using_drip_irrigation_if_no_zero__continuous  \\\n",
      "n_outliers                                             2.000000                                \n",
      "pct_outliers                                           0.746269                                \n",
      "\n",
      "              ...  Q0__positive_total__continuous  \\\n",
      "n_outliers    ...                       12.000000   \n",
      "pct_outliers  ...                        4.477612   \n",
      "\n",
      "              Q0__negative_total__continuous  \\\n",
      "n_outliers                         10.000000   \n",
      "pct_outliers                        3.731343   \n",
      "\n",
      "              Q0__Positive_Negative_Score__continuous  \\\n",
      "n_outliers                                   1.000000   \n",
      "pct_outliers                                 0.373134   \n",
      "\n",
      "              Q0__Distance__continuous  Q0__TOTAL_AREA__continuous  \\\n",
      "n_outliers                   42.000000                   164.00000   \n",
      "pct_outliers                 15.671642                    61.19403   \n",
      "\n",
      "              Q0__self_control_score__continuous  \\\n",
      "n_outliers                                   0.0   \n",
      "pct_outliers                                 0.0   \n",
      "\n",
      "              Q0__target1_yearly_income_from_agr_per_land_SQM__continuous  \\\n",
      "n_outliers                                            13.000000             \n",
      "pct_outliers                                           4.850746             \n",
      "\n",
      "              Q0__target2_yearly_income_from_agr_USD__continuous  \\\n",
      "n_outliers                                            17.000000    \n",
      "pct_outliers                                           6.343284    \n",
      "\n",
      "              Q0__target3_veg_per_area__continuous  \\\n",
      "n_outliers                                9.000000   \n",
      "pct_outliers                              3.358209   \n",
      "\n",
      "              Q0__sustainable_livelihood_score__continuous  \n",
      "n_outliers                                        4.000000  \n",
      "pct_outliers                                      1.492537  \n",
      "\n",
      "[2 rows x 27 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2071753757.py:23: RuntimeWarning: divide by zero encountered in divide\n",
      "  robust_z = (data - med) / qn\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2071753757.py:23: RuntimeWarning: invalid value encountered in divide\n",
      "  robust_z = (data - med) / qn\n"
     ]
    }
   ],
   "source": [
    "print(\"applied robust z-score outlier flagging to nepal:\")\n",
    "outlier_indices_nepal, robust_z_scores_nepal = robust_z_scores(nepal_df, non_cat_cols_nepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "b490dcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied robust z-score outlier flagging to senegal:\n",
      "Outliers per column (using Qn):\n",
      "              Q1__Latitude__continuous  Q1__Longitude__continuous  \\\n",
      "n_outliers                   72.000000                 106.000000   \n",
      "pct_outliers                 21.492537                  31.641791   \n",
      "\n",
      "              Q1__Altitude__continuous  Q1__Accuracy__continuous  \\\n",
      "n_outliers                    5.000000                 28.000000   \n",
      "pct_outliers                  1.492537                  8.358209   \n",
      "\n",
      "              Q5__Age__continuous  Q0__Hope_total__continuous  \\\n",
      "n_outliers                    0.0                   20.000000   \n",
      "pct_outliers                  0.0                    5.970149   \n",
      "\n",
      "              Q0__Average_CS__continuous  \\\n",
      "n_outliers                     15.000000   \n",
      "pct_outliers                    4.477612   \n",
      "\n",
      "              Q60__Land_owned_cultivated_ha__continuous  \\\n",
      "n_outliers                                          0.0   \n",
      "pct_outliers                                        0.0   \n",
      "\n",
      "              Q61__Land_rented_cultivated_ha__continuous  \\\n",
      "n_outliers                                     33.000000   \n",
      "pct_outliers                                    9.850746   \n",
      "\n",
      "              Q62__Land_grow_vegetables_ha__continuous  ...  \\\n",
      "n_outliers                                         0.0  ...   \n",
      "pct_outliers                                       0.0  ...   \n",
      "\n",
      "              Q90__Yearly_income_agriculture_XOF__continuous  \\\n",
      "n_outliers                                         23.000000   \n",
      "pct_outliers                                        6.865672   \n",
      "\n",
      "              Q91__Yearly_income_overall_XOF__continuous  \\\n",
      "n_outliers                                      9.000000   \n",
      "pct_outliers                                    2.686567   \n",
      "\n",
      "              Q92__Current_loan_amount_XOF__continuous  \\\n",
      "n_outliers                                   51.000000   \n",
      "pct_outliers                                 15.223881   \n",
      "\n",
      "              Q0__Distance_Thies_KM__continuous  \\\n",
      "n_outliers                           105.000000   \n",
      "pct_outliers                          31.343284   \n",
      "\n",
      "              Q0__Distance_Dakar_KM__continuous  \\\n",
      "n_outliers                           240.000000   \n",
      "pct_outliers                          71.641791   \n",
      "\n",
      "              Q0__Age_Education_interaction__continuous  \\\n",
      "n_outliers                                     2.000000   \n",
      "pct_outliers                                   0.597015   \n",
      "\n",
      "              Q0__target1_yearly_income_from_agr_per_land_SQM__continuous  \\\n",
      "n_outliers                                            31.000000             \n",
      "pct_outliers                                           9.253731             \n",
      "\n",
      "              Q0__target2_yearly_income_from_agr_USD__continuous  \\\n",
      "n_outliers                                            23.000000    \n",
      "pct_outliers                                           6.865672    \n",
      "\n",
      "              Q0__target3_veg_per_area__continuous  \\\n",
      "n_outliers                               39.000000   \n",
      "pct_outliers                             11.641791   \n",
      "\n",
      "              Q0__sustainable_livelihood_score__continuous  \n",
      "n_outliers                                        7.000000  \n",
      "pct_outliers                                      2.089552  \n",
      "\n",
      "[2 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2071753757.py:23: RuntimeWarning: divide by zero encountered in divide\n",
      "  robust_z = (data - med) / qn\n",
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\2071753757.py:23: RuntimeWarning: invalid value encountered in divide\n",
      "  robust_z = (data - med) / qn\n"
     ]
    }
   ],
   "source": [
    "print(\"applied robust z-score outlier flagging to senegal:\")\n",
    "outlier_indices_senegal, robust_z_scores_senegal = robust_z_scores(senegal_df, non_cat_cols_senegal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crosschecking with the QQ plots and marginal distributions of a lot of these features, many of these values classified as outliers make sense in terms of the data and should not be classified as such (especially in the ordinal columns), took a handful of columns frome each dataset for which there could be outliers, calculated robust z scores in order to identify outliers (greater than threshold=3.0). For the productivity column outliers we simply remove rows with outliers. For any of the other columns we perform winsorization, defining the caps using the qn scale used to calculate the robust z scores (med +- threshold*qn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "83448286",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_cols_nepal = ['Q62__How_much_VEGETABLES_do_you_harvest_per_year_from_this_plot_kilograms__continuous',\n",
    "                      'Q78__How_many_years_have_you_been_using_drip_irrigation_if_no_zero__continuous',\n",
    "                      'Q108__What_is_your_households_yearly_income_from_agriculture_NPR__continuous',\n",
    "                      'Q109__What_is_your_households_yearly_income_overall_including_agriculture_NPR__continuous',\n",
    "                      'Q101__how_many_people_live_in_this_household__continuous',\n",
    "                      'Q0__self_control_score__continuous', \n",
    "                      'Q0__hope_total__continuous',\n",
    "                      'Q0__positive_total__continuous',\n",
    "                      'Q0__negative_total__continuous',\n",
    "                      'Q0__Positive_Negative_Score__continuous',]\n",
    "\n",
    "outlier_cols_senegal = ['Q0__Hope_total__continuous',\n",
    "                        'Q71__VEG_harvest_per_year_kg__continuous',\n",
    "                        'Q87__Household_size__continuous',\n",
    "                        'Q90__Yearly_income_agriculture_XOF__continuous',\n",
    "                        'Q91__Yearly_income_overall_XOF__continuous',\n",
    "                        'Q92__Current_loan_amount_XOF__continuous',]\n",
    "\n",
    "\n",
    "target_cols = ['Q0__target1_yearly_income_from_agr_per_land_SQM__continuous',\n",
    "               'Q0__target2_yearly_income_from_agr_USD__continuous',\n",
    "               'Q0__target3_veg_per_area__continuous']\n",
    "\n",
    "def handle_outliers(\n",
    "    df: pd.DataFrame,\n",
    "    outlier_cols: list[str],\n",
    "    target_cols:  list[str],\n",
    "    threshold:   float = 3.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1. Remove rows where any column in `target_cols` has |robust z-score| > threshold.\n",
    "    2. For each column in `outlier_cols`, winsorize at median ± threshold * Qn scale.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "      Original data.\n",
    "    outlier_cols : list of str\n",
    "      Columns to winsorize.\n",
    "    target_cols : list of str\n",
    "      Columns whose outliers trigger row removal.\n",
    "    threshold : float\n",
    "      Robust z-score cutoff (uses Qn scale from statsmodels.robust.scale).\n",
    "    \"\"\"\n",
    "    df2 = df.copy()\n",
    "\n",
    "    # ── Step 1: Drop rows with extreme targets ──────────────────────────────\n",
    "    drop_mask = pd.Series(False, index=df2.index)\n",
    "    for col in target_cols:\n",
    "        vals = df2[col].dropna().values\n",
    "        if len(vals) == 0:\n",
    "            continue\n",
    "\n",
    "        med = np.median(vals)\n",
    "        qn  = robust.scale.qn_scale(vals)\n",
    "        if qn == 0:\n",
    "            continue\n",
    "\n",
    "        z = (df2[col] - med) / qn\n",
    "        drop_mask |= z.abs() > threshold\n",
    "\n",
    "    df2 = df2.loc[~drop_mask].reset_index(drop=True)\n",
    "\n",
    "    # ── Step 2: Winsorize outlier_cols ─────────────────────────────────────\n",
    "    for col in outlier_cols:\n",
    "        series = df2[col]\n",
    "        non_na = series.dropna()\n",
    "        if non_na.empty:\n",
    "            continue\n",
    "\n",
    "        med = np.median(non_na.values)\n",
    "        qn  = robust.scale.qn_scale(non_na.values)\n",
    "        if qn == 0:\n",
    "            continue\n",
    "\n",
    "        # define the cap bounds\n",
    "        lower_cap = med - threshold * qn\n",
    "        upper_cap = med + threshold * qn\n",
    "\n",
    "        # winsorize: anything below lower_cap → lower_cap; above upper_cap → upper_cap\n",
    "        df2[col] = series.clip(lower=lower_cap, upper=upper_cap)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "41372f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepal_df = handle_outliers(nepal_df, outlier_cols_nepal, target_cols)\n",
    "senegal_df = handle_outliers(senegal_df, outlier_cols_senegal, target_cols)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all categorical and binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "a660ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_nepal = []\n",
    "cat_cols_senegal = []\n",
    "for col in nepal_df.columns:\n",
    "    meta_type = parse_feature_metadata(col)['type']\n",
    "    if meta_type not in ['continuous', 'discrete', 'time']:\n",
    "        cat_cols_nepal.append(col)\n",
    "\n",
    "for col in senegal_df.columns:\n",
    "    meta_type = parse_feature_metadata(col)['type']\n",
    "    if meta_type not in ['continuous', 'discrete', 'time']:\n",
    "        cat_cols_senegal.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that none have an overly large amount of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "ad23aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with ≤20 categories:\n",
      " Q105__main_sources_of_income__nominal                                                          19\n",
      "Q53__What_type_of_crop_is_grown_on_this_plot__nominal                                          14\n",
      "Q65__Do_you_do_any_of_the_following__nominal                                                   12\n",
      "Q8__WardNumber__nominal                                                                        10\n",
      "Q21__Hope_5_I_am_easily_downed_being_at_a_low_position_brought_down_in_an_argument__ordinal     9\n",
      "                                                                                               ..\n",
      "Q55__For_Vegetables_do_you_use_improved_and_or_variety_seeds_yes__binary__1                     2\n",
      "Q57__If_you_self_prepare_seedlings_how_Nursery__binary__1                                       2\n",
      "Q70__in_the_past_12_months_did_you_receive_any_info_from_anyone_on_agriculture__binary__1       2\n",
      "Q58__fertilizer_on_this_plot__nominal                                                           2\n",
      "Q60__do_you_use_pesticides_or_herbicides_on_this_plot_Yes__binary__1                            1\n",
      "Length: 74, dtype: int64\n",
      "\n",
      "Columns with >20 categories:\n",
      " Q4__PhoneNumberAndIsZeroIfNone__nominal                            227\n",
      "Q9__NameOfVillage__nominal                                          99\n",
      "Q64__Do_you_use_machinery_or_and_equipment_on_the_plot__nominal     23\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_counts = nepal_df[cat_cols_nepal].nunique()\n",
    "# 3. see which columns are OK (≤20) or not (>20)\n",
    "ok      = unique_counts[ unique_counts <= 20 ]\n",
    "too_many = unique_counts[ unique_counts  > 20 ]\n",
    "\n",
    "print(\"Columns with ≤20 categories:\\n\", ok.sort_values(ascending=False))\n",
    "print(\"\\nColumns with >20 categories:\\n\", too_many.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "1cd44730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with ≤20 categories:\n",
      " Q7__name_of_village__nominal                                         16\n",
      "Q14__Hope_4_There_are_lots_of_ways_around_any_problem__ordinal        9\n",
      "Q13__Hope_3_I_feel_tired_most_of_the_time__ordinal                    8\n",
      "Q12__Hope_2_I_energetically_pursue_my_goals__ordinal                  8\n",
      "Q11__Hope_1_I_can_think_of_many_ways_to_get_out_of_a_jam__ordinal     8\n",
      "                                                                     ..\n",
      "Q76__Received_agri_info_last_12m__binary__1                           2\n",
      "Q0__Has_Education_Yes_No__binary__1                                   2\n",
      "Q86__Sex_male__binary__1                                              2\n",
      "Q69__Use_pesticide_or_herbicide__binary__1                            2\n",
      "Q63__CROP__nominal                                                    2\n",
      "Length: 73, dtype: int64\n",
      "\n",
      "Columns with >20 categories:\n",
      " Q4__Phone_Number__nominal    92\n",
      "Q73__Machinery__nominal      26\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_counts = senegal_df[cat_cols_senegal].nunique()\n",
    "# 3. see which columns are OK (≤20) or not (>20)\n",
    "ok      = unique_counts[ unique_counts <= 20 ]\n",
    "too_many = unique_counts[ unique_counts  > 20 ]\n",
    "\n",
    "print(\"Columns with ≤20 categories:\\n\", ok.sort_values(ascending=False))\n",
    "print(\"\\nColumns with >20 categories:\\n\", too_many.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only telephone, village and machinery columns have large amounts of categories which makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove all remaining columns that have only a single value as this adds no new information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepal_df = nepal_df.loc[:, nepal_df.nunique(dropna=False) > 1]\n",
    "senegal_df = senegal_df.loc[:, senegal_df.nunique(dropna=False) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aa7564-6482-42fe-b687-17eab44ef07e",
   "metadata": {},
   "source": [
    "# Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the feature groups that we will be interested in throughout this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "2a833729",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPAL_CAT_COL_NAMES = {'Q11': 'Marital_Status',\n",
    " 'Q53': 'What_type_of_crop_is_grown_on_this_plot',\n",
    " 'Q54': 'For_vegetables_what_is_your_source_of_seeds',\n",
    " 'Q56': 'For_vegetables_do_you_use_seedlings',\n",
    " 'Q58': 'fertilizer_on_this_plot',\n",
    " 'Q63': 'What_is_the_main_use_of_produce_from_holding',\n",
    " 'Q64': 'Do_you_use_machinery_or_and_equipment_on_the_plot',\n",
    " 'Q65': 'Do_you_do_any_of_the_following',\n",
    " 'Q67': 'What_do_you_use_soil_analysis_for',\n",
    " 'Q68': 'How_do_you_conduct_soil_analysis',\n",
    " 'Q69': 'What_is_correct_for_you',\n",
    " 'Q71': 'in_the_past_12_months_from_who_did_you_receive_info_on_agriculture',\n",
    " 'Q73': 'Did_you_receive_anything_from_these_organizations',\n",
    " 'Q74': 'How_do_you_decide_to_plow',\n",
    " 'Q75': 'How_do_you_decide_to_begin_sowing',\n",
    " 'Q76': 'What_type_of_irrigation_do_you_use',\n",
    " 'Q100': 'Caste',\n",
    " 'Q105': 'main_sources_of_income',\n",
    " 'Q111': 'Generally_speaking_would_you_say_that_most_people_can_be_trusted',\n",
    " 'Q112': 'I_am_much_better_than_most_farmers_here',\n",
    " 'Q113': 'dislike_not_knowing_what_is_going_to_happen'}\n",
    "\n",
    "SENEGAL_CAT_COL_NAMES = {'Q63': 'CROP',\n",
    " 'Q64': 'Seed_source',\n",
    " 'Q65': 'Variety',\n",
    " 'Q66': 'Seedlings',\n",
    " 'Q67': 'Fertilizer',\n",
    " 'Q72': 'Sold_VEG',\n",
    " 'Q73': 'Machinery',\n",
    " 'Q74': 'Practice',\n",
    " 'Q77': 'Info_source',\n",
    " 'Q79': 'Did_you_receive_anything_from_the_specified_organizations',\n",
    " 'Q80': 'Plow_weather',\n",
    " 'Q81': 'Sow',\n",
    " 'Q82': 'Irrigation',\n",
    " 'Q88': 'family_main_sources_income',\n",
    " 'Q89': 'education_level'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "07259e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Geographic features\n",
    "geo_features_nepal = [\n",
    "    \"Q1__Latitude__continuous\",\n",
    "    \"Q1__Longitude__continuous\",\n",
    "    \"Q7__District__nominal\",\n",
    "    \"Q8__WardNumber__nominal\",\n",
    "    \"Q9__NameOfVillage__nominal\",\n",
    "    \"Q1__Altitude__continuous\",\n",
    "    \"Q1__Accuracy__continuous\",\n",
    "]\n",
    "\n",
    "geo_features_senegal = [\n",
    "    \"Q1__Latitude__continuous\",\n",
    "    \"Q1__Longitude__continuous\",\n",
    "    \"Q6__Arrondissement__nominal\",\n",
    "    \"Q7__name_of_village__nominal\",\n",
    "    \"Q1__Altitude__continuous\",\n",
    "    \"Q1__Accuracy__continuous\",\n",
    "]\n",
    "\n",
    "# 2) Feelings items (PANAS)\n",
    "feelings_features_nepal = [\n",
    "    \"Q30__To_what_extent_you_have_felt_this_way_during_the_past_week_interested__ordinal\",\n",
    "    \"Q31__To_what_extent_you_have_felt_this_way_during_the_past_week_Distressed_worried__ordinal\",\n",
    "    \"Q32__To_what_extent_you_have_felt_this_way_during_the_past_week_Excited__ordinal\",\n",
    "    \"Q33__To_what_extent_you_have_felt_this_way_during_the_past_week_Upset__ordinal\",\n",
    "    \"Q34__To_what_extent_you_have_felt_this_way_during_the_past_week_Strong__ordinal\",\n",
    "    \"Q35__To_what_extent_you_have_felt_this_way_during_the_past_week_Guilty__ordinal\",\n",
    "    \"Q36__To_what_extent_you_have_felt_this_way_during_the_past_week_Scared__ordinal\",\n",
    "    \"Q37__To_what_extent_you_have_felt_this_way_during_the_past_week_Hostile__ordinal\",\n",
    "    \"Q38__To_what_extent_you_have_felt_this_way_during_the_past_week_Enthusiastic__ordinal\",\n",
    "    \"Q39__To_what_extent_you_have_felt_this_way_during_the_past_week_Proud__ordinal\",\n",
    "    \"Q40__To_what_extent_you_have_felt_this_way_during_the_past_week_Irritable__ordinal\",\n",
    "    \"Q41__To_what_extent_you_have_felt_this_way_during_the_past_week_Alert__ordinal\",\n",
    "    \"Q42__To_what_extent_you_have_felt_this_way_during_the_past_week_Ashamed__ordinal\",\n",
    "    \"Q43__To_what_extent_you_have_felt_this_way_during_the_past_week_Inspired__ordinal\",\n",
    "    \"Q44__To_what_extent_you_have_felt_this_way_during_the_past_week_Nervous__ordinal\",\n",
    "    \"Q45__To_what_extent_you_have_felt_this_way_during_the_past_week_Determined__ordinal\",\n",
    "    \"Q46__To_what_extent_you_have_felt_this_way_during_the_past_week_Attentive__ordinal\",\n",
    "    \"Q47__To_what_extent_you_have_felt_this_way_during_the_past_week_Jittery__ordinal\",\n",
    "    \"Q48__To_what_extent_you_have_felt_this_way_during_the_past_week_Active__ordinal\",\n",
    "    \"Q49__To_what_extent_you_have_felt_this_way_during_the_past_week_Afraid__ordinal\",\n",
    "]\n",
    "\n",
    "# 3) Character-strength items (Senegal)\n",
    "character_features_senegal = [\n",
    "    \"Q24__Stand_up_in_face_of_opposition__ordinal\",\n",
    "    \"Q25__Never_quit_task_before_done__ordinal\",\n",
    "    \"Q26__Always_keep_promises__ordinal\",\n",
    "    \"Q27__Always_finish_what_I_start__ordinal\",\n",
    "    \"Q28__Leader_treats_everyone_equally__ordinal\",\n",
    "    \"Q29__Always_busy_with_something_interesting__ordinal\",\n",
    "    \"Q30__Strength_help_group_work_together__ordinal\",\n",
    "    \"Q31__Must_stand_up_for_beliefs__ordinal\",\n",
    "    \"Q32__Finish_things_despite_obstacles__ordinal\",\n",
    "    \"Q33__Everyones_rights_equally_important__ordinal\",\n",
    "    \"Q34__Excited_by_many_activities__ordinal\",\n",
    "    \"Q35__Always_coming_up_with_new_ways__ordinal\",\n",
    "    \"Q36__People_describe_me_as_wise__ordinal\",\n",
    "    \"Q37__Promises_can_be_trusted__ordinal\",\n",
    "    \"Q38__Give_everyone_a_chance__ordinal\",\n",
    "    \"Q39__Effective_leader_treats_same__ordinal\",\n",
    "    \"Q40__Extremely_grateful_person__ordinal\",\n",
    "    \"Q41__Look_forward_to_each_new_day__ordinal\",\n",
    "    \"Q42__Friends_say_I_have_many_ideas__ordinal\",\n",
    "    \"Q43__Always_stand_up_for_beliefs__ordinal\",\n",
    "    \"Q44__True_to_own_values__ordinal\",\n",
    "    \"Q45__Think_through_consequences_before_acting__ordinal\",\n",
    "    \"Q46__Have_lots_of_energy__ordinal\",\n",
    "    \"Q47__Find_interest_in_any_situation__ordinal\",\n",
    "    \"Q48__Thinking_things_through_is_part_of_me__ordinal\",\n",
    "    \"Q49__Original_thinker__ordinal\",\n",
    "    \"Q50__Mature_view_on_life__ordinal\",\n",
    "    \"Q51__Feel_thankful_for_what_I_have__ordinal\",\n",
    "    \"Q52__Always_weigh_pros_and_cons__ordinal\",\n",
    "    \"Q53__Very_careful_person__ordinal\",\n",
    "    \"Q54__Try_to_have_good_reasons_for_decisions__ordinal\",\n",
    "    \"Q55__Always_make_careful_choices__ordinal\",\n",
    "    \"Q56__Feel_profound_appreciation_daily__ordinal\",\n",
    "    \"Q57__Awaken_with_excitement__ordinal\",\n",
    "    \"Q58__Others_consider_me_wise__ordinal\",\n",
    "    \"Q59__Worth_listening_to_everyones_opinion__ordinal\",\n",
    "]\n",
    "\n",
    "# 4) Demographics\n",
    "demo_features_nepal = [\n",
    "    \"Q10__SexMale__binary__1\",\n",
    "    \"Q11__Marital_Status__nominal\",\n",
    "]\n",
    "\n",
    "demo_features_senegal = [\n",
    "    \"Q86__Sex_male__binary__1\",\n",
    "]\n",
    "\n",
    "# 5) Hope scale\n",
    "hope_features_nepal = [\n",
    "    \"Q17__Hope_1_I_Can_Think_Of_Many_Ways_To_Get_Out_Of_A_Jam__ordinal\",\n",
    "    \"Q18__Hope_2_I_energetically_pursue_my_goals__ordinal\",\n",
    "    \"Q19__Hope_3_I_feel_tired_most_of_the_time__ordinal\",\n",
    "    \"Q20__Hope_4_There_are_lots_of_ways_around_any_problem__ordinal\",\n",
    "    \"Q21__Hope_5_I_am_easily_downed_being_at_a_low_position_brought_down_in_an_argument__ordinal\",\n",
    "    \"Q22__Hope_6_I_can_think_of_many_ways_to_get_the_things_in_life_that_are_important_to_me__ordinal\",\n",
    "    \"Q23__Hope_7_I_worry_about_my_health__ordinal\",\n",
    "    \"Q24__Hope_8_Even_when_others_get_discouraged_I_know_I_can_find_a_way_to_solve_the_problem__ordinal\",\n",
    "    \"Q25__Hope_9_My_past_experiences_have_prepared_me_well_for_my_future__ordinal\",\n",
    "    \"Q26__Hope_10_I_have_been_pretty_successful_in_life__ordinal\",\n",
    "    \"Q27__Hope_11_I_usually_find_myself_worrying_about_something__ordinal\",\n",
    "    \"Q28__Hope_12_I_meet_the_goals_that_I_set_for_myself__ordinal\",\n",
    "]\n",
    "\n",
    "hope_features_senegal = [\n",
    "    \"Q11__Hope_1_I_can_think_of_many_ways_to_get_out_of_a_jam__ordinal\",\n",
    "    \"Q12__Hope_2_I_energetically_pursue_my_goals__ordinal\",\n",
    "    \"Q13__Hope_3_I_feel_tired_most_of_the_time__ordinal\",\n",
    "    \"Q14__Hope_4_There_are_lots_of_ways_around_any_problem__ordinal\",\n",
    "    \"Q15__Hope_5_I_am_easily_downed_in_an_argument__ordinal\",\n",
    "    \"Q16__Hope_6_I_can_think_of_many_ways_to_get_the_things_in_life_that_are_important_to_me__ordinal\",\n",
    "    \"Q17__Hope_7_I_worry_about_my_health__ordinal\",\n",
    "    \"Q18__Hope_8_Even_when_others_get_discouraged_I_know_I_can_find_a_way__ordinal\",\n",
    "    \"Q19__Hope_9_My_past_experiences_have_prepared_me_well_for_my_future__ordinal\",\n",
    "    \"Q20__Hope_10_Ive_been_pretty_successful_in_life__ordinal\",\n",
    "    \"Q21__Hope_11_I_usually_find_myself_worrying_about_something__ordinal\",\n",
    "    \"Q22__Hope_12_I_meet_the_goals_that_I_set_for_myself__ordinal\",\n",
    "]\n",
    "\n",
    "# 6) Crop & fertilizer\n",
    "crop_fertilizer_features_nepal = [\n",
    "    \"Q53__What_type_of_crop_is_grown_on_this_plot__nominal\",\n",
    "    \"Q54__For_vegetables_what_is_your_source_of_seeds__nominal\",\n",
    "    \"Q55__For_Vegetables_do_you_use_improved_and_or_variety_seeds_yes__binary__1\",\n",
    "    \"Q56__For_vegetables_do_you_use_seedlings__nominal\",\n",
    "    \"Q57__If_you_self_prepare_seedlings_how_Nursery__binary__1\",\n",
    "    \"Q58__fertilizer_on_this_plot__nominal\",\n",
    "]\n",
    "\n",
    "crop_fertilizer_features_senegal = [\n",
    "    \"Q63__CROP__nominal\",\n",
    "    \"Q64__Seed_source__nominal\",\n",
    "    \"Q65__Variety__nominal\",\n",
    "    \"Q66__Seedlings__nominal\",\n",
    "    \"Q67__Fertilizer__nominal\",\n",
    "]\n",
    "\n",
    "# 7) Plot-level practices\n",
    "plot_practice_features_nepal = [\n",
    "    \"Q63__What_is_the_main_use_of_produce_from_holding__nominal\",\n",
    "    \"Q64__Do_you_use_machinery_or_and_equipment_on_the_plot__nominal\",\n",
    "    \"Q65__Do_you_do_any_of_the_following__nominal\",\n",
    "]\n",
    "\n",
    "plot_practice_features_senegal = [\n",
    "    \"Q69__Use_pesticide_or_herbicide__binary__1\",\n",
    "    \"Q72__Sold_VEG__nominal\",\n",
    "    \"Q73__Machinery__nominal\",\n",
    "    \"Q74__Practice__nominal\",\n",
    "]\n",
    "\n",
    "soil_features_senegal = [\n",
    "    \"Q76__Received_agri_info_last_12m__binary__1\",\n",
    "    \"Q77__Info_source__nominal\",\n",
    "    \"Q78__Names_of_organizations__nominal\",\n",
    "    \"Q79__Did_you_receive_anything_from_the_specified_organizations__nominal\",\n",
    "]\n",
    "\n",
    "# 9) Plowing, sowing & irrigation\n",
    "plow_irrigation_features_nepal = [\n",
    "    \"Q74__How_do_you_decide_to_plow__nominal\",\n",
    "    \"Q75__How_do_you_decide_to_begin_sowing__nominal\",\n",
    "    \"Q76__What_type_of_irrigation_do_you_use__nominal\",\n",
    "]\n",
    "\n",
    "plow_irrigation_features_senegal = [\n",
    "    \"Q80__Plow_weather__nominal\",\n",
    "    \"Q81__Sow__nominal\",\n",
    "    \"Q82__Irrigation__nominal\",\n",
    "    \"Q84__Years_using_drip_irrigation__continuous\",\n",
    "]\n",
    "\n",
    "# 10) Self-control items\n",
    "self_control_features_nepal = [\n",
    "    \"Q80__SC_1_When_I_do_a_boring_job_I_think_about_the_less_boring_parts_of_the_job__ordinal\",\n",
    "    \"Q81__SC_2_By_changing_my_way_of_thinking_I_am_often_able_to_change_my_feelings_about_almost_everything__ordinal\",\n",
    "    \"Q82__SC_3_I_often_find_it_difficult_to_overcome_my_feelings_of_nervousness_and_tension_without_help__ordinal\",\n",
    "    \"Q83__SC_4_When_I_am_feeling_depressed_I_try_to_think_about_pleasant_events__ordinal\",\n",
    "    \"Q84__SC_5_I_cannot_help_thinking_about_mistakes_I_made__ordinal\",\n",
    "    \"Q85__SC_6_I_usually_do_what_I_am_supposed_to_do_more_quickly_when_someone_is_pressuring_me__ordinal\",\n",
    "    \"Q86__SC_7_When_I_am_faced_with_a_difficult_decision_I_prefer_to_postpone_it__ordinal\",\n",
    "    \"Q87__SC_8_When_I_try_to_get_rid_of_a_bad_habit_for_example_smoking_stealing_i_first_try_to_find_out_why_i_have_the_habit__ordinal\",\n",
    "    \"Q88__SC_9_If_I_smoked_two_packs_of_cigarettes_a_day_I_would_need_help_to_stop_smoking__ordinal\",\n",
    "    \"Q89__SC_10_When_I_feel_down_I_try_to_act_cheerful_so_that_my_mood_will_change__ordinal\",\n",
    "    \"Q90__SC_11_I_tend_to_postpone_unpleasant_tasks__ordinal\",\n",
    "    \"Q91__SC_12_I_prefer_to_finish_a_job_that_I_have_to_do_before_I_start_doing_things_I_really_like__ordinal\",\n",
    "    \"Q92__SC_13_When_I_feel_pain_I_try_not_to_think_about_it__ordinal\",\n",
    "    \"Q93__SC_14_My_selfesteem_increases_when_I_am_able_to_overcome_a_bad_habit__ordinal\",\n",
    "    \"Q94__SC_15_When_I_feel_that_I_am_too_impulsive_I_tell_myself_to_stop_and_think_before_I_do_anything__ordinal\",\n",
    "    \"Q95__SC_16_Even_when_I_am_terribly_angry_at_someone_I_consider_my_actions_very_carefully__ordinal\",\n",
    "    \"Q96__SC_17_When_I_need_to_make_a_decision_I_try_to_look_for_different_alternative__ordinal\",\n",
    "    \"Q97__SC_18_Usually_I_first_do_the_thing_I_really_like_to_do_even_if_there_are_more_urgent_things_to_do__ordinal\",\n",
    "    \"Q98__SC_19_When_I_am_faced_with_a_number_of_things_to_do_I_usually_plan_my_work__ordinal\",\n",
    "    \"Q99__SC_20_When_I_am_tired_and_I_have_no_opportunity_to_sleep_I_try_not_to_think_about_it__ordinal\",\n",
    "]\n",
    "\n",
    "# 11) Household, income & trust\n",
    "household_features_nepal = [\n",
    "    \"Q100__Caste__nominal\",\n",
    "    \"Q101__how_many_people_live_in_this_household__continuous\",\n",
    "    \"Q105__main_sources_of_income__nominal\",\n",
    "    \"Q106__Education_level_of_this_person_that_is_interviewed_years_of_formal_education__continuous\",\n",
    "    \"Q107__Education_level_of_your_wife_husband_How_many_years_of_formal_education__continuous\",\n",
    "    \"Q110__Do_you_currently_have_a_loan_if_no_zero_if_yes_amount_of_money_loaned_NPR__continuous\",\n",
    "    \"Q111__Generally_speaking_would_you_say_that_most_people_can__ordinal\",\n",
    "]\n",
    "\n",
    "household_features_senegal = [\n",
    "    \"Q85__Group__nominal\",\n",
    "    \"Q87__Household_size__continuous\",\n",
    "    \"Q88__family_main_sources_income__nominal\",\n",
    "    \"Q89__education_level__nominal\",\n",
    "    \"Q0__Has_Education_Yes_No__binary__1\",\n",
    "    \"Q0__Education_years__continuous\",\n",
    "    \"Q92__Current_loan_amount_XOF__continuous\",\n",
    "    \"Q93__Trust_most_people__ordinal\",\n",
    "]\n",
    "\n",
    "# 12) Indices & aggregates\n",
    "hope_index_nepal            = [\"Q0__hope_total__continuous\"]\n",
    "hope_index_senegal          = [\"Q0__Hope_total__continuous\"]\n",
    "self_control_index_nepal  = [\"Q0__self_control_score__continuous\"]\n",
    "positive_index_nepal        = [\"Q0__positive_total__continuous\"]\n",
    "negative_index_nepal        = [\"Q0__negative_total__continuous\"]\n",
    "avg_farming_practices_nepal = [\"Q0__average_of_farming_practices__ordinal\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot scatter plots with LOESS between numeric / ordinal columns and the targets and boxplots for binary and nominal features against the targets for each of the above defined groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "044ed5ed-e646-4633-8202-9a6b20af44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "BINARY = 1\n",
    "SINGLE_DUMMY = 2\n",
    "ONE_HOT = 3\n",
    "MULTI_SELECT = 4\n",
    "\n",
    "\n",
    "def robust_loess(x, y, **kwargs):\n",
    "    fitted = lowess(endog=y, exog=x, frac=0.6667, it=3)\n",
    "    plt.plot(fitted[:, 0], fitted[:, 1], **kwargs)\n",
    "\n",
    "# 3) pairplot function\n",
    "\n",
    "def plot_pairplots(df, expl_feats, target_feats):\n",
    "\n",
    "    # 2) for each target, plot *only* expl → target\n",
    "    for tgt in target_feats:\n",
    "        tmeta = parse_feature_metadata(tgt)\n",
    "        if not tmeta:\n",
    "            continue\n",
    "        tname = f\"{tmeta['qid']}_{tmeta['name']}\"\n",
    "\n",
    "        # assemble data\n",
    "        tmp = df[expl_feats].copy()\n",
    "        tmp[tname] = df[tgt]\n",
    "        tmp = tmp.dropna()\n",
    "        if tmp.shape[0] < 2:\n",
    "            continue\n",
    "\n",
    "        # i) compute grid shape\n",
    "        n = len(expl_feats)\n",
    "        ncols = int(math.ceil(math.sqrt(n)))\n",
    "        nrows = int(math.ceil(n / ncols))\n",
    "\n",
    "        # ii) create subplots grid\n",
    "        fig, axes = plt.subplots(nrows, ncols,\n",
    "                                 figsize=(ncols * 4, nrows * 3),\n",
    "                                 squeeze=False)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # iii) plot each explanatory feature\n",
    "        for i, exp in enumerate(expl_feats):\n",
    "            ax = axes[i]\n",
    "            meta = parse_feature_metadata(exp)\n",
    "            expl_type = meta.get('type', None)\n",
    "\n",
    "            if expl_type in ['continuous', 'discrete', 'ordinal']:\n",
    "                x = tmp[exp]\n",
    "                y = tmp[tname]\n",
    "\n",
    "                # if this is ordinal (labels), convert to ordered categorical codes\n",
    "                if expl_type == 'ordinal' or pd.api.types.is_categorical_dtype(x):\n",
    "                    cat = pd.Categorical(x, ordered=True)\n",
    "                    x_codes = cat.codes\n",
    "                    # scatter & LOESS on codes\n",
    "                    ax.scatter(x_codes, y, alpha=0.6)\n",
    "                    fitted = lowess(endog=y, exog=x_codes, frac=0.6667, it=3)\n",
    "                    ax.plot(fitted[:, 0], fitted[:, 1], color='r')\n",
    "                    # relabel x-ticks with the category names\n",
    "                    ax.set_xticks(range(len(cat.categories)))\n",
    "                    ax.set_xticklabels(cat.categories,\n",
    "                                       rotation=45, ha='right', fontsize=8)\n",
    "                else:\n",
    "                    # purely numeric\n",
    "                    ax.scatter(x, y, alpha=0.6)\n",
    "                    fitted = lowess(endog=y, exog=x, frac=0.6667, it=3)\n",
    "                    ax.plot(fitted[:, 0], fitted[:, 1], color='r')\n",
    "\n",
    "            elif expl_type in ['nominal', 'binary']:\n",
    "\n",
    "                # detect multi-select (list entries) vs. single-select (scalars)\n",
    "                is_multi = tmp[exp].apply(lambda x: isinstance(x, (list, tuple))).any()\n",
    "                if is_multi:\n",
    "                    # --- multi-select nominal: explode lists so each label gets its own box ---\n",
    "                    df_expl = tmp[[exp, tname]].explode(exp)\n",
    "                    df_expl = df_expl.dropna(subset=[exp])\n",
    "                    sns.boxplot(x=df_expl[exp].astype(str),\n",
    "                                y=df_expl[tname],\n",
    "                                ax=ax)\n",
    "                else:\n",
    "                    levels = tmp[exp].astype(str).value_counts().index\n",
    "                    if len(levels) <= 10:\n",
    "                        sns.boxplot(x=tmp[exp].astype(str), y=tmp[tname], ax=ax)\n",
    "                        #ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
    "                        #make x ticks wrap like done for the xlabel below\n",
    "                    else:\n",
    "                        top_levels = tmp[exp].astype(str).value_counts().nlargest(10).index\n",
    "                        tmp2 = tmp[tmp[exp].astype(str).isin(top_levels)]\n",
    "                        sns.boxplot(x=tmp2[exp].astype(str), y=tmp2[tname], ax=ax)\n",
    "                        #ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
    "                        #make x ticks wrap like done for the xlabel below\n",
    "\n",
    "                orig_labels = [lbl.get_text() for lbl in ax.get_xticklabels()]\n",
    "                wrapped_labels = [\"\\n\".join([lab[i:i+30] for i in range(0, len(lab), 30)]) for lab in orig_labels]\n",
    "                ax.set_xticklabels(wrapped_labels, rotation=45, ha='right', fontsize=8)\n",
    "\n",
    "            # per-axis label\n",
    "            wrapped_label = \"\\n\".join([exp[i:i+30] for i in range(0, len(exp), 30)])\n",
    "            ax.set_xlabel(wrapped_label, fontsize=8, labelpad=8)\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        # turn off leftover axes\n",
    "        for ax in axes[n:]:\n",
    "            ax.set_visible(False)\n",
    "\n",
    "        # tidy and title\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"Explanatory Features vs {tname}\", y=1.02)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# 4) heatmap function\n",
    "\n",
    "def plot_heatmaps(df, expl_feats, target_feats, method='pearson'):\n",
    "    # 1) subset to numeric explanatory + numeric targets\n",
    "    sub = df[expl_feats + target_feats].copy()\n",
    "    # 2) coerce any object/nominal into codes\n",
    "    for c in sub.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(sub[c]):\n",
    "            sub[c] = sub[c].astype(\"category\").cat.codes\n",
    "    # 3) compute corr\n",
    "    corr = sub.corr(method=method).loc[expl_feats, target_feats]\n",
    "    plt.figure(figsize=(len(target_feats)*0.5+3, len(expl_feats)*0.3+3))\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"vlag\", center=0)\n",
    "    plt.title(\"Correlation heatmap: explanatory vs target\", pad=20)\n",
    "    plt.show()\n",
    "\n",
    "def plot_group_heatmap(df, features, method='pearson'):\n",
    "\n",
    "    sub = df[features].copy()\n",
    "    # coerce nominal into codes\n",
    "    for c in sub.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(sub[c]):\n",
    "            sub[c] = sub[c].astype(\"category\").cat.codes\n",
    "    corr = sub.corr(method=method)\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"viridis\", center=0)\n",
    "    plt.title(\"Correlation heatmap: group\", pad=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d874988-d617-4fda-93da-123db7bbb9a4",
   "metadata": {},
   "source": [
    "## Geography & Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "56a8a847-fa49-4358-a858-4711c41f23b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, geo_features_nepal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "aa00b6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, geo_features_nepal, target_cols)\n",
    "    plot_group_heatmap(nepal_df, geo_features_nepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "ad8f6a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, geo_features_nepal, target_cols, 'spearman')\n",
    "    plot_group_heatmap(nepal_df, geo_features_nepal, 'spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "0af68b0a-6688-4a56-8968-46704f1624af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, geo_features_senegal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "0ccfb516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, geo_features_senegal, target_cols)\n",
    "    plot_group_heatmap(senegal_df, geo_features_senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "3db642ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, geo_features_senegal, target_cols, 'spearman')\n",
    "    plot_group_heatmap(senegal_df, geo_features_senegal, 'spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ddbfb-623e-44e0-98d0-4c482037de0f",
   "metadata": {},
   "source": [
    "### Check Visually on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "b9a666df-6118-404f-aed4-ddee8c8f5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import contextily as ctx\n",
    "\n",
    "def map_targets_on_map(\n",
    "    df,\n",
    "    lon_col,\n",
    "    lat_col,\n",
    "    target_cols,\n",
    "    basemap=True,\n",
    "    figsize=(8, 8),\n",
    "    cmap='viridis',\n",
    "    marker_size=50\n",
    "):\n",
    "    \"\"\"\n",
    "    For each target variable, plot its spatial distribution on a map.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame containing data\n",
    "    - lon_col, lat_col: names of longitude and latitude columns\n",
    "    - target_cols: list of target variable names to map\n",
    "    - basemap: whether to include a background map (default True)\n",
    "    - figsize: size of the matplotlib figure\n",
    "    - cmap: colormap for target values\n",
    "    - marker_size: size of plotted points\n",
    "    \"\"\"\n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df.copy(),\n",
    "        geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    # Project to Web Mercator for basemap\n",
    "    gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    for target in target_cols:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        gdf.plot(\n",
    "            ax=ax,\n",
    "            column=target,\n",
    "            cmap=cmap,\n",
    "            legend=True,\n",
    "            markersize=marker_size\n",
    "        )\n",
    "        if basemap:\n",
    "            # Attempt Stamen terrain; fallback to OSM if unavailable\n",
    "            try:\n",
    "                provider = ctx.providers.Stamen.Terrain\n",
    "            except Exception:\n",
    "                provider = ctx.providers.OpenStreetMap.Mapnik\n",
    "            ctx.add_basemap(ax, source=provider)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(f\"Spatial distribution of {target}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "dca3385d-28ec-4913-a8f2-a47d15e32520",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    map_targets_on_map(nepal_df, 'Q1__Longitude__continuous', 'Q1__Latitude__continuous', target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "46bfbb6f-b375-4779-8669-b39c6d594a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    map_targets_on_map(senegal_df, 'Q1__Longitude__continuous', 'Q1__Latitude__continuous', target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d9b6a-a8a1-4e32-a8d1-9347f297ab59",
   "metadata": {},
   "source": [
    "## Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, demo_features_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "9291f321-9b1b-4883-b693-75d5bed11ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, demo_features_senegal, target_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416f23c-effc-459b-b667-c934a8341198",
   "metadata": {},
   "source": [
    "## Hope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "441a028c-80d3-4c61-a848-5ae7c1116b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, hope_features_nepal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "489be7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, hope_features_nepal, target_cols)\n",
    "    plot_group_heatmap(nepal_df, hope_features_nepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "fb7a5f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, hope_features_nepal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(nepal_df, hope_features_nepal, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "2f993d12-3f5d-44dd-b9a7-46c9db742bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, hope_features_senegal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "956634c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, hope_features_senegal, target_cols)\n",
    "    plot_group_heatmap(senegal_df, hope_features_senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "12abf047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, hope_features_senegal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(senegal_df, hope_features_senegal, method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc2fa1-8104-4fc7-a2b2-15dc9ccee05e",
   "metadata": {},
   "source": [
    "## Crop & Fertilizer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "8f5c0fb5-9491-40e4-9b76-da64e660ccb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, crop_fertilizer_features_nepal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "fcd659be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, crop_fertilizer_features_nepal, target_cols)\n",
    "    plot_group_heatmap(nepal_df, crop_fertilizer_features_nepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "d6b9c9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, crop_fertilizer_features_nepal, target_cols, 'spearman')\n",
    "    plot_group_heatmap(nepal_df, crop_fertilizer_features_nepal, 'spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "8aad5857-8219-4134-b8bb-6ff83173f8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, crop_fertilizer_features_senegal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "4bc09418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, crop_fertilizer_features_senegal, target_cols)\n",
    "    plot_group_heatmap(senegal_df, crop_fertilizer_features_senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "60ae4444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, crop_fertilizer_features_senegal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(senegal_df, crop_fertilizer_features_senegal, method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de25d2bd-0579-4ce4-a8a7-33e424092983",
   "metadata": {},
   "source": [
    "## Pest Control & Machinery & Weeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "1b930121-3818-4dd2-9c06-490cb92fd6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, plot_practice_features_nepal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, plot_practice_features_nepal, target_cols)\n",
    "    plot_group_heatmap(nepal_df, plot_practice_features_nepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, plot_practice_features_nepal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(nepal_df, plot_practice_features_nepal, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "7b5329c3-b8a3-4b7a-891f-16bd104934e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, plot_practice_features_senegal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, plot_practice_features_senegal, target_cols)\n",
    "    plot_group_heatmap(senegal_df, plot_practice_features_senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, plot_practice_features_senegal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(senegal_df, plot_practice_features_senegal, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "d9a0c452-4014-4d5f-b399-99be4078e586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, soil_features_senegal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, soil_features_senegal, target_cols)\n",
    "    plot_group_heatmap(senegal_df, soil_features_senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, soil_features_senegal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(senegal_df, soil_features_senegal, method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc428a-11f3-425e-bd5a-fe88df355d9c",
   "metadata": {},
   "source": [
    "## Plowing, Sowing & Irrigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, plow_irrigation_features_nepal, target_cols)\n",
    "    plot_group_heatmap(nepal_df, plow_irrigation_features_nepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, plow_irrigation_features_nepal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(nepal_df, plow_irrigation_features_nepal, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "cb9b0f99-2e06-421b-94ac-9934f5cabbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, plow_irrigation_features_senegal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, plow_irrigation_features_senegal, target_cols)\n",
    "    plot_group_heatmap(senegal_df, plow_irrigation_features_senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, plow_irrigation_features_senegal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(senegal_df, plow_irrigation_features_senegal, method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac01c7-e8a0-474d-8d08-4186d313c2c4",
   "metadata": {},
   "source": [
    "## Self-control Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "8aae485c-e014-4902-b8e8-17e4cb7dffa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, self_control_features_nepal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, plow_irrigation_features_senegal, target_cols)\n",
    "    plot_group_heatmap(senegal_df, plow_irrigation_features_senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, plow_irrigation_features_senegal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(senegal_df, plow_irrigation_features_senegal, method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aacd0d0-7ec9-43d1-9c51-0d619993e902",
   "metadata": {},
   "source": [
    "## Household & Income & Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "4a035d6c-9c9e-417b-9c08-14ca9659be4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, household_features_nepal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, household_features_nepal, target_cols)\n",
    "    plot_group_heatmap(nepal_df, household_features_nepal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, household_features_nepal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(nepal_df, household_features_nepal, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "06041150-9d1e-4c25-8872-b59dfbceb890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, household_features_senegal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, household_features_senegal, target_cols)\n",
    "    plot_group_heatmap(senegal_df, household_features_senegal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, household_features_senegal, target_cols, method='spearman')\n",
    "    plot_group_heatmap(senegal_df, household_features_senegal, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, self_control_index_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, self_control_index_nepal, target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, self_control_index_nepal, target_cols, method='spearman')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, hope_index_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, hope_index_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, hope_index_nepal, target_cols, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, hope_index_senegal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, hope_index_senegal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(senegal_df, hope_index_senegal, target_cols, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "7b33cdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, positive_index_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "da7eb2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, positive_index_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "82901c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, positive_index_nepal, target_cols, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "32a5e609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, negative_index_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "cf2d427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, negative_index_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "b45f98a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, negative_index_nepal, target_cols, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "5567e862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, avg_farming_practices_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "119a14b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, avg_farming_practices_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "73c2af6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, avg_farming_practices_nepal, target_cols, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "66267376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(nepal_df, feelings_features_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "18396615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, PEARSON CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, PEARSON CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, feelings_features_nepal, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "a18787a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL DATA, SPEARMAN CORR\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL DATA, SPEARMAN CORR\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_heatmaps(nepal_df, feelings_features_nepal, target_cols, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "e4763e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL DATA\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL DATA\")\n",
    "if PLOT_GRAPHS:\n",
    "    plot_pairplots(senegal_df, character_features_senegal, target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e70c42",
   "metadata": {},
   "source": [
    "## Productivity Metrics Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "267f27ef-4551-43b3-9f45-c0b0f1e7844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    plot_group_heatmap(nepal_df, target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "0a20248c-cde7-4931-9461-c308cda44802",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    plot_group_heatmap(senegal_df, target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd8cc1-be9a-4c37-9c9a-f155db36bbe6",
   "metadata": {},
   "source": [
    "# Second Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change phone number column to just binary yes no if he has a phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "6a43998a-d55a-4492-a0a5-16bbbf475d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nepal_df['Q4__PhoneNumberAndIsZeroIfNone__nominal'] = (nepal_df['Q4__PhoneNumberAndIsZeroIfNone__nominal'] == 0).astype(int)\n",
    "senegal_df['Q4__Phone_Number__nominal'] = (senegal_df['Q4__Phone_Number__nominal'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "b66175a1-0a27-4daa-9b14-a223f27bed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepal_df.rename(columns={'Q4__PhoneNumberAndIsZeroIfNone__nominal' : 'Q4__HasPhoneNumber__binary__1'}, inplace=True)\n",
    "senegal_df.rename(columns={'Q4__Phone_Number__nominal' : 'Q4__HasPhoneNumber__binary__1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale all numeric columns and one hot encode all categorical columns, and deal with missing values in categorical columns by adding a 'missing' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "86db7c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q17__Hope_1_I_Can_Think_Of_Many_Ways_To_Get_Out_Of_A_Jam__ordinal</th>\n",
       "      <th>Q18__Hope_2_I_energetically_pursue_my_goals__ordinal</th>\n",
       "      <th>Q19__Hope_3_I_feel_tired_most_of_the_time__ordinal</th>\n",
       "      <th>Q20__Hope_4_There_are_lots_of_ways_around_any_problem__ordinal</th>\n",
       "      <th>Q21__Hope_5_I_am_easily_downed_being_at_a_low_position_brought_down_in_an_argument__ordinal</th>\n",
       "      <th>Q22__Hope_6_I_can_think_of_many_ways_to_get_the_things_in_life_that_are_important_to_me__ordinal</th>\n",
       "      <th>Q23__Hope_7_I_worry_about_my_health__ordinal</th>\n",
       "      <th>Q24__Hope_8_Even_when_others_get_discouraged_I_know_I_can_find_a_way_to_solve_the_problem__ordinal</th>\n",
       "      <th>Q25__Hope_9_My_past_experiences_have_prepared_me_well_for_my_future__ordinal</th>\n",
       "      <th>Q26__Hope_10_I_have_been_pretty_successful_in_life__ordinal</th>\n",
       "      <th>Q27__Hope_11_I_usually_find_myself_worrying_about_something__ordinal</th>\n",
       "      <th>Q28__Hope_12_I_meet_the_goals_that_I_set_for_myself__ordinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Q17__Hope_1_I_Can_Think_Of_Many_Ways_To_Get_Out_Of_A_Jam__ordinal  \\\n",
       "0                                                    3                   \n",
       "1                                                    6                   \n",
       "2                                                    5                   \n",
       "3                                                    6                   \n",
       "4                                                    5                   \n",
       "..                                                 ...                   \n",
       "239                                                  8                   \n",
       "240                                                  7                   \n",
       "241                                                  8                   \n",
       "242                                                  7                   \n",
       "243                                                  7                   \n",
       "\n",
       "     Q18__Hope_2_I_energetically_pursue_my_goals__ordinal  \\\n",
       "0                                                    5      \n",
       "1                                                    7      \n",
       "2                                                    7      \n",
       "3                                                    6      \n",
       "4                                                    6      \n",
       "..                                                 ...      \n",
       "239                                                  7      \n",
       "240                                                  8      \n",
       "241                                                  8      \n",
       "242                                                  8      \n",
       "243                                                  8      \n",
       "\n",
       "     Q19__Hope_3_I_feel_tired_most_of_the_time__ordinal  \\\n",
       "0                                                    3    \n",
       "1                                                    2    \n",
       "2                                                    2    \n",
       "3                                                    5    \n",
       "4                                                    3    \n",
       "..                                                 ...    \n",
       "239                                                  2    \n",
       "240                                                  5    \n",
       "241                                                  4    \n",
       "242                                                  5    \n",
       "243                                                  5    \n",
       "\n",
       "     Q20__Hope_4_There_are_lots_of_ways_around_any_problem__ordinal  \\\n",
       "0                                                    6                \n",
       "1                                                    6                \n",
       "2                                                    6                \n",
       "3                                                    7                \n",
       "4                                                    6                \n",
       "..                                                 ...                \n",
       "239                                                  8                \n",
       "240                                                  7                \n",
       "241                                                  7                \n",
       "242                                                  7                \n",
       "243                                                  7                \n",
       "\n",
       "     Q21__Hope_5_I_am_easily_downed_being_at_a_low_position_brought_down_in_an_argument__ordinal  \\\n",
       "0                                                    6                                             \n",
       "1                                                    1                                             \n",
       "2                                                    5                                             \n",
       "3                                                    4                                             \n",
       "4                                                    4                                             \n",
       "..                                                 ...                                             \n",
       "239                                                  1                                             \n",
       "240                                                  2                                             \n",
       "241                                                  5                                             \n",
       "242                                                  4                                             \n",
       "243                                                  5                                             \n",
       "\n",
       "     Q22__Hope_6_I_can_think_of_many_ways_to_get_the_things_in_life_that_are_important_to_me__ordinal  \\\n",
       "0                                                    6                                                  \n",
       "1                                                    7                                                  \n",
       "2                                                    7                                                  \n",
       "3                                                    6                                                  \n",
       "4                                                    7                                                  \n",
       "..                                                 ...                                                  \n",
       "239                                                  7                                                  \n",
       "240                                                  6                                                  \n",
       "241                                                  7                                                  \n",
       "242                                                  7                                                  \n",
       "243                                                  8                                                  \n",
       "\n",
       "     Q23__Hope_7_I_worry_about_my_health__ordinal  \\\n",
       "0                                               8   \n",
       "1                                               8   \n",
       "2                                               8   \n",
       "3                                               6   \n",
       "4                                               8   \n",
       "..                                            ...   \n",
       "239                                             5   \n",
       "240                                             8   \n",
       "241                                             8   \n",
       "242                                             8   \n",
       "243                                             8   \n",
       "\n",
       "     Q24__Hope_8_Even_when_others_get_discouraged_I_know_I_can_find_a_way_to_solve_the_problem__ordinal  \\\n",
       "0                                                    7                                                    \n",
       "1                                                    5                                                    \n",
       "2                                                    5                                                    \n",
       "3                                                    7                                                    \n",
       "4                                                    6                                                    \n",
       "..                                                 ...                                                    \n",
       "239                                                  5                                                    \n",
       "240                                                  5                                                    \n",
       "241                                                  6                                                    \n",
       "242                                                  7                                                    \n",
       "243                                                  6                                                    \n",
       "\n",
       "     Q25__Hope_9_My_past_experiences_have_prepared_me_well_for_my_future__ordinal  \\\n",
       "0                                                    6                              \n",
       "1                                                    7                              \n",
       "2                                                    7                              \n",
       "3                                                    8                              \n",
       "4                                                    5                              \n",
       "..                                                 ...                              \n",
       "239                                                  8                              \n",
       "240                                                  8                              \n",
       "241                                                  8                              \n",
       "242                                                  7                              \n",
       "243                                                  7                              \n",
       "\n",
       "     Q26__Hope_10_I_have_been_pretty_successful_in_life__ordinal  \\\n",
       "0                                                    6             \n",
       "1                                                    6             \n",
       "2                                                    5             \n",
       "3                                                    6             \n",
       "4                                                    5             \n",
       "..                                                 ...             \n",
       "239                                                  6             \n",
       "240                                                  8             \n",
       "241                                                  8             \n",
       "242                                                  7             \n",
       "243                                                  7             \n",
       "\n",
       "     Q27__Hope_11_I_usually_find_myself_worrying_about_something__ordinal  \\\n",
       "0                                                    6                      \n",
       "1                                                    5                      \n",
       "2                                                    7                      \n",
       "3                                                    4                      \n",
       "4                                                    6                      \n",
       "..                                                 ...                      \n",
       "239                                                  3                      \n",
       "240                                                  5                      \n",
       "241                                                  4                      \n",
       "242                                                  5                      \n",
       "243                                                  5                      \n",
       "\n",
       "     Q28__Hope_12_I_meet_the_goals_that_I_set_for_myself__ordinal  \n",
       "0                                                    4             \n",
       "1                                                    6             \n",
       "2                                                    6             \n",
       "3                                                    6             \n",
       "4                                                    5             \n",
       "..                                                 ...             \n",
       "239                                                  6             \n",
       "240                                                  7             \n",
       "241                                                  7             \n",
       "242                                                  7             \n",
       "243                                                  7             \n",
       "\n",
       "[244 rows x 12 columns]"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nepal_df[hope_features_nepal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "49ba8311-2a30-4a81-bacc-7a6cb451805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "\n",
    "def scale_numeric_columns(df, scale_ordinal=True):\n",
    "    df = df.copy()\n",
    "    # Get non-categorical numeric columns\n",
    "    cols_to_scale = [col for col in df.columns if parse_feature_metadata(col)[\"type\"] in ['continuous', 'discrete', 'ordinal' if scale_ordinal else None]]\n",
    "\n",
    "    for col in cols_to_scale:\n",
    "        median = df[col].median()\n",
    "        # this returns a new Series (up-cast to float64) and assigns it back\n",
    "        df[col] = df[col].fillna(median)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "\n",
    "    return df\n",
    "\n",
    "def deal_with_missing_in_cat_cols(df):\n",
    "\n",
    "    nom_cols = [col for col in df.columns if parse_feature_metadata(col)[\"type\"] in ['nominal']]\n",
    "    ord_cols = [col for col in df.columns if parse_feature_metadata(col)[\"type\"] in ['ordinal']]\n",
    "\n",
    "    # deal with missing by adding a 'Missing' category\n",
    "    for col in nom_cols:\n",
    "        df[col] = df[col].astype('category').cat.add_categories('Missing')\n",
    "        df[col] = df[col].fillna('Missing')\n",
    "    for col in ord_cols:\n",
    "        # Find the mode of the 'category' column\n",
    "        mode_value = df[col].astype('category').mode()[0]\n",
    "        # Fill missing values with the mode\n",
    "        df[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "def one_hot_encode_columns(df):\n",
    "    df = df.copy()\n",
    "    cols_to_dummies = []\n",
    "    cols_to_dummies_prefixes = []\n",
    "    for col in df.columns:\n",
    "        meta = parse_feature_metadata(col)\n",
    "        if meta[\"type\"] in ['ordinal', 'nominal']:\n",
    "            # add it to columns to one hot encode along with its question number\n",
    "            cols_to_dummies_prefixes.append(f\"{meta['qid']}__{meta['name']}\")\n",
    "            cols_to_dummies.append((col, meta[\"type\"]))\n",
    "    \n",
    "    col_names_to_dummies, _ = zip(*cols_to_dummies) \n",
    "    col_names_to_dummies = list(col_names_to_dummies)\n",
    "    # applying prefix to dummies according to our feature name format\n",
    "    dummies = pd.get_dummies(df[col_names_to_dummies], prefix_sep='_', prefix=cols_to_dummies_prefixes, columns=col_names_to_dummies, dtype=int)\n",
    "    \n",
    "    def reformat(col):\n",
    "        qid, name = col.split(\"__\")\n",
    "        return f\"{qid}__{re.sub(r'[^A-Za-z0-9_]', '', name)}\"\n",
    "\n",
    "    dummies = dummies.rename(columns=reformat)\n",
    "\n",
    "    # applying postfix to dummies according to our feature name format\n",
    "    rename_map = {}\n",
    "    for orig, type in cols_to_dummies:\n",
    "        # find all dummy cols that start with \"<orig's qid>-<orig's name>\"\n",
    "        group = [c for c in dummies.columns if c.startswith(f\"{parse_feature_metadata(orig)['qid']}__{parse_feature_metadata(orig)['name']}\")]\n",
    "        # enumerate them 1,2,3…\n",
    "        for i, col_name in enumerate(group, start=1):\n",
    "            rename_map[col_name] = f\"{col_name}__binary_{type}__{i}\"\n",
    "            \n",
    "    dummies = dummies.rename(columns=rename_map)\n",
    "    df_other = df.drop(columns=col_names_to_dummies)\n",
    "    final_df = pd.concat([df_other, dummies], axis=1)\n",
    "    \n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "713db33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nominals(df):\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        if parse_feature_metadata(col)['type'] == 'nominal':\n",
    "            cols.append(col)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "38ad1761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ordinal_to_numeric(df):\n",
    "    for col in df.columns:\n",
    "        if parse_feature_metadata(col)['type'] == 'ordinal':\n",
    "            df[col] = df[col].apply(lambda x: int(x[-1]) if isinstance(x, (str)) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "e53874af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def reduce_to_index(df: pd.DataFrame,\n",
    "                    cols: list[str],\n",
    "                    new_col_name: str = \"PC1\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs PCA on the specified columns of df and replaces them with the first component.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Your input DataFrame.\n",
    "    cols : list of str\n",
    "        List of exactly four column names in df to be reduced.\n",
    "    new_col_name : str, default=\"PC1\"\n",
    "        Name of the new column for the first principal component.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of df where the four columns in `cols` are dropped and replaced\n",
    "        by `new_col_name`, containing the first principal component scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Standardize the selected columns\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df[cols])\n",
    "    \n",
    "    # 2. Fit PCA and transform\n",
    "    pca = PCA(n_components=4).fit(X_scaled)\n",
    "    scores = pca.transform(X_scaled)\n",
    "\n",
    "    # 3. Build the variance-weighted composite index of the first two PCs\n",
    "    var_props = pca.explained_variance_ratio_[:2]\n",
    "    weights = var_props / var_props.sum()\n",
    "    index = (scores[:, :2] * weights).sum(1)\n",
    "\n",
    "    # 4. Construct the new DataFrame\n",
    "    df_out = df.copy()\n",
    "    df_out[new_col_name] = index\n",
    "    df_out = df_out.drop(columns=cols)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "541e0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['Q0__target1_yearly_income_from_agr_per_land_SQM__continuous',\n",
    "               'Q0__target2_yearly_income_from_agr_USD__continuous',\n",
    "               'Q0__target3_veg_per_area__continuous',\n",
    "               'Q0__target4_self_farming_perception__ordinal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a43faf",
   "metadata": {},
   "source": [
    "Supervisor asked us to not use specific psychological indicators in our final method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "7f974c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEPAL_HOPE_QUESTIONS_RANGE = list(range(17,29))\n",
    "NEPAL_FEELINGS_QUESTIONS_RANGE = list(range(30, 50))\n",
    "NEPAL_SELF_CONTROL_QUESTIONS_RANGE = list(range(80, 100))\n",
    "NEPAL_PSYCH_QUESTION_RANGE = NEPAL_HOPE_QUESTIONS_RANGE \\\n",
    "                            + NEPAL_FEELINGS_QUESTIONS_RANGE \\\n",
    "                            + NEPAL_SELF_CONTROL_QUESTIONS_RANGE\n",
    "\n",
    "SENEGAL_HOPE_QUESTIONS_RANGE = list(range(11,23))\n",
    "SENEGAL_CHARACTER_STRENGTH_QUESTIONS_RANGE = list(range(24, 60))\n",
    "SENEGAL_PSYCH_QUESTION_RANGE = SENEGAL_HOPE_QUESTIONS_RANGE \\\n",
    "                                + SENEGAL_CHARACTER_STRENGTH_QUESTIONS_RANGE\n",
    "\n",
    "NEPAL_ADDITIONAL = [\"Q1__Latitude__continuous\", \"Q1__Longitude__continuous\", \"Q1__Accuracy__continuous\", \"Q50__How_much_land_that_is_yours_do_you_cultivate_bigha__continuous\",\n",
    "                    \"Q51__How_much_land_that_is_rented_or_leased_do_you_cultivate_bigha__continuous\", \"Q62__How_much_VEGETABLES_do_you_harvest_per_year_from_this_plot_kilograms__continuous\",\n",
    "                    \"Q108__What_is_your_households_yearly_income_from_agriculture_NPR__continuous\", \"Q52__On_how_much_land_do_you_grow_vegetables_bigha__continuous\",\n",
    "                    \"Q57__If_you_self_prepare_seedlings_how_Nursery__binary__1\", \"Q55__For_Vegetables_do_you_use_improved_and_or_variety_seeds_yes__binary__1\",\n",
    "                    \"Q10__SexMale__binary__1\", \"Q0__positive_total__continuous\", \"Q0__negative_total__continuous\"]\n",
    "SENEGAL_ADDITIONAL = [\"Q1__Latitude__continuous\", \"Q1__Longitude__continuous\", \"Q1__Accuracy__continuous\", \"Q60__Land_owned_cultivated_ha__continuous\", \"Q61__Land_rented_cultivated_ha__continuous\",\n",
    "                      \"Q71__VEG_harvest_per_year_kg__continuous\", \"Q90__Yearly_income_agriculture_XOF__continuous\", \"Q69__Use_pesticide_or_herbicide__binary__1\", \"Q0__Distance_Thies_KM__continuous\",\n",
    "                      \"Q0__Distance_Dakar_KM__continuous\", \"Q62__Land_grow_vegetables_ha__continuous\"]\n",
    "\n",
    "def drop_ordinal_psych_columns(df, country):\n",
    "    for col in df.columns:\n",
    "        qid = int(parse_feature_metadata(col)[\"qid\"].replace('Q', ''))\n",
    "        if country == \"NEPAL\" and (qid in NEPAL_PSYCH_QUESTION_RANGE or col in NEPAL_ADDITIONAL):\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "        if country == \"SENEGAL\" and (qid in SENEGAL_PSYCH_QUESTION_RANGE or col in SENEGAL_ADDITIONAL):\n",
    "            df.drop(col, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "5790d3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\677600633.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "convert_ordinal_to_numeric(nepal_df)\n",
    "deal_with_missing_in_cat_cols(nepal_df)\n",
    "nepal_df_to_save = reduce_to_index(nepal_df, target_cols, new_col_name='Q0__AGR_PROD__continuous')\n",
    "# No need to scale when using correlation matrix\n",
    "#nepal_df_to_save = scale_numeric_columns(nepal_df_to_save, scale_ordinal=False)\n",
    "drop_ordinal_psych_columns(nepal_df_to_save, \"NEPAL\")\n",
    "nepal_df_to_save.to_excel(\"nepal_dataframe_FA.xlsx\")\n",
    "nepal_nominals = get_nominals(nepal_df_to_save)\n",
    "nepal_df_nominals = one_hot_encode_columns(nepal_df_to_save[nepal_nominals])\n",
    "nepal_df_to_save = nepal_df_to_save.drop(columns=nepal_nominals)\n",
    "nepal_df_to_save = pd.concat((nepal_df_to_save.reset_index(drop=True), nepal_df_nominals.reset_index(drop=True)), axis=1)\n",
    "nepal_df_to_save.to_excel(\"nepal_dataframe_SEM.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "571f0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepal_df = one_hot_encode_columns(nepal_df)\n",
    "nepal_df = scale_numeric_columns(nepal_df, scale_ordinal=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "40d1faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadav\\AppData\\Local\\Temp\\ipykernel_30844\\677600633.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "convert_ordinal_to_numeric(senegal_df)\n",
    "deal_with_missing_in_cat_cols(senegal_df)\n",
    "senegal_df_to_save = reduce_to_index(senegal_df, target_cols, new_col_name='Q0__AGR_PROD__continuous')\n",
    "# No need to scale when using correlation matrix\n",
    "#senegal_df_to_save = scale_numeric_columns(senegal_df_to_save, scale_ordinal=False)\n",
    "drop_ordinal_psych_columns(senegal_df_to_save, \"SENEGAL\")\n",
    "senegal_df_to_save.to_excel(\"senegal_dataframe_FA.xlsx\")\n",
    "senegal_nominals = get_nominals(senegal_df_to_save)\n",
    "senegal_df_nominals = one_hot_encode_columns(senegal_df_to_save[senegal_nominals])\n",
    "senegal_df_to_save = senegal_df_to_save.drop(columns=senegal_nominals)\n",
    "senegal_df_to_save = pd.concat((senegal_df_to_save.reset_index(drop=True), senegal_df_nominals.reset_index(drop=True)), axis=1)\n",
    "senegal_df_to_save.to_excel(\"senegal_dataframe_SEM.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "abbb1659-9714-41eb-9325-5b2195a48b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "senegal_df = one_hot_encode_columns(senegal_df)\n",
    "senegal_df = scale_numeric_columns(senegal_df, scale_ordinal=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0f4aa-5d9f-4b7c-86f3-b09f8f87760e",
   "metadata": {},
   "source": [
    "# Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "d9b8675d-cb90-4e3a-8255-d8e61fa1b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_group_to_dummies(df, group : list):\n",
    "    dummy_group = []\n",
    "    for orig in group:\n",
    "        meta = parse_feature_metadata(orig)\n",
    "        if meta['type'] not in ['ordinal', 'nominal']:\n",
    "            if orig in df.columns:\n",
    "                dummy_group.append(orig)    \n",
    "        else:    \n",
    "            for col in df.columns:\n",
    "                if col.startswith(f\"{meta['qid']}__{meta['name']}\"):\n",
    "                    dummy_group.append(col)\n",
    "                \n",
    "    return dummy_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "ec1aa555-8d02-4cee-b70b-b2189b0caad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {'Geographic Features': (geo_features_nepal, geo_features_senegal),\n",
    "          'Demographic Features': (demo_features_nepal, demo_features_senegal),\n",
    "          'Hope Features': (hope_features_nepal, hope_features_senegal),\n",
    "          'Crop & Fertilizer Features':(crop_fertilizer_features_nepal, crop_fertilizer_features_senegal),\n",
    "          'Plot Practice Features': (plot_practice_features_nepal, plot_practice_features_senegal),\n",
    "          'Plow & Irrigation': (plow_irrigation_features_nepal, plow_irrigation_features_senegal),\n",
    "          'Self-control Features': (self_control_features_nepal, None),\n",
    "          'Household Features': (household_features_nepal, household_features_senegal)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "3a009693-93ac-4d7d-8fae-f6870182f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.stats.distance import permanova, DistanceMatrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from gower import gower_matrix          # pip install gower\n",
    "# X_enc = result of your pipeline's fit_transform\n",
    "\n",
    "def transform(df, X_features, Y_features):\n",
    "    # — X side: impute, drop zero‐var, cast to float —\n",
    "    X_df    = df[X_features].copy().fillna(df[X_features].median())\n",
    "    mask_x  = X_df.std(ddof=0) > 0\n",
    "    X_enc   = X_df.loc[:, mask_x].astype(float).values\n",
    "\n",
    "    # — Y side: as before —\n",
    "    Y_df    = df[Y_features].copy().fillna(df[Y_features].median())\n",
    "    stds    = Y_df.std(ddof=0)\n",
    "    keep    = stds > 0\n",
    "    Y_enc   = (Y_df.loc[:, keep] - Y_df.loc[:, keep].mean()) / stds[keep]\n",
    "\n",
    "    return X_enc, Y_enc\n",
    "\n",
    "\n",
    "def convert_to_dist_matrices(X_enc, Y_enc):\n",
    "    D = gower_matrix(X_enc)\n",
    "    print(\"shape of D:\", D.shape)\n",
    "    print(\"any NaNs in D?\", np.isnan(D).any())\n",
    "    print(\"is D symmetric?\", np.allclose(D, D.T, equal_nan=False))\n",
    "    DX = DistanceMatrix(gower_matrix(X_enc))\n",
    "    DY = DistanceMatrix(gower_matrix(Y_enc))\n",
    "    return DX, DY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "7370e7f5-5cc9-4f81-9399-b0431ae4c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.stats.distance import mantel\n",
    "\n",
    "def mantel_test(DX, DY):\n",
    "    mantel_r, mantel_p, _ = mantel(DX, DY, method='spearman', permutations=999)\n",
    "    print(f\"Mantel ρ = {mantel_r:.3f},  p = {mantel_p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "2b672539-d85d-44af-9027-c5dd3b21ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dcor\n",
    "\n",
    "def distance_covariance_test(X_enc, Y_enc):\n",
    "    dcov_p, dcov_stat = dcor.independence.distance_covariance_test(\n",
    "        X_enc, Y_enc, num_resamples=999)\n",
    "\n",
    "    print(f\"dCov statistic = {dcov_stat:.4f},  p = {dcov_p:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "7ff8b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nepal_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "14642fed-92bf-47e3-9e94-e4bfc6013094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mantel and dCov tests on the Geographic Features:\n",
      "shape of D: (244, 244)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.001,  p = 0.9800\n",
      "dCov statistic = 17.0628,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Demographic Features:\n",
      "shape of D: (244, 244)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.035,  p = 0.3820\n",
      "dCov statistic = 1.6352,  p = 0.1000\n",
      "\n",
      "Mantel and dCov tests on the Hope Features:\n",
      "shape of D: (244, 244)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.069,  p = 0.0010\n",
      "dCov statistic = 23.7343,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Crop & Fertilizer Features:\n",
      "shape of D: (244, 244)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.417,  p = 0.0010\n",
      "dCov statistic = 64.5079,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Plot Practice Features:\n",
      "shape of D: (244, 244)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.293,  p = 0.0010\n",
      "dCov statistic = 45.0307,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Plow & Irrigation:\n",
      "shape of D: (244, 244)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.483,  p = 0.0010\n",
      "dCov statistic = 85.9884,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Self-control Features:\n",
      "shape of D: (244, 244)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.057,  p = 0.0070\n",
      "dCov statistic = 38.4690,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Household Features:\n",
      "shape of D: (244, 244)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.135,  p = 0.0010\n",
      "dCov statistic = 34.9273,  p = 0.0010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_features = convert_group_to_dummies(nepal_df, target_cols)\n",
    "for key, value in groups.items():\n",
    "    print(f\"Mantel and dCov tests on the {key}:\")\n",
    "    X_feats = convert_group_to_dummies(nepal_df, value[0])\n",
    "    X_enc, Y_enc = transform(nepal_df, X_feats, Y_features)\n",
    "\n",
    "    # no need to re-drop X here, we do both in convert_to_dist_matrices\n",
    "    DX, DY = convert_to_dist_matrices(X_enc, Y_enc)\n",
    "\n",
    "    mantel_test(DX, DY)\n",
    "    distance_covariance_test(X_enc, Y_enc)   # still runs on raw arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "47621043-2685-45e3-ae8c-68c83b6ed82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mantel and dCov tests on the Geographic Features:\n",
      "shape of D: (274, 274)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.069,  p = 0.0010\n",
      "dCov statistic = 44.3139,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Demographic Features:\n",
      "shape of D: (274, 274)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.005,  p = 0.7890\n",
      "dCov statistic = 1.6847,  p = 0.0050\n",
      "\n",
      "Mantel and dCov tests on the Hope Features:\n",
      "shape of D: (274, 274)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.150,  p = 0.0010\n",
      "dCov statistic = 30.6487,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Crop & Fertilizer Features:\n",
      "shape of D: (274, 274)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.016,  p = 0.3820\n",
      "dCov statistic = 7.4604,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Plot Practice Features:\n",
      "shape of D: (274, 274)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.443,  p = 0.0010\n",
      "dCov statistic = 86.3505,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Plow & Irrigation:\n",
      "shape of D: (274, 274)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.077,  p = 0.0010\n",
      "dCov statistic = 14.3206,  p = 0.0010\n",
      "\n",
      "Mantel and dCov tests on the Household Features:\n",
      "shape of D: (274, 274)\n",
      "any NaNs in D? False\n",
      "is D symmetric? True\n",
      "Mantel ρ = 0.096,  p = 0.0010\n",
      "dCov statistic = 29.1311,  p = 0.0010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_features = convert_group_to_dummies(senegal_df, target_cols)\n",
    "for key in groups.keys():\n",
    "    if 'Self-control' in key:\n",
    "        continue\n",
    "    print(f\"Mantel and dCov tests on the {key}:\")\n",
    "    X_features = convert_group_to_dummies(senegal_df, groups[key][1])\n",
    "    X_enc, Y_enc = transform(senegal_df, X_features, Y_features)\n",
    "    DX, DY = convert_to_dist_matrices(X_enc, Y_enc)\n",
    "    mantel_test(DX, DY)\n",
    "    distance_covariance_test(X_enc, Y_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d761daa-f805-4fb1-9c72-dd630061c918",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "b13c0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "0515af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_explained_variance_for_group_for_pca(df, group_name, group_features):\n",
    "    # Perform PCA with additional components\n",
    "    pca_full = PCA(n_components=min(len(group_features),10))  # Analyze up to 10 components\n",
    "    pca_full_result = pca_full.fit_transform(df[group_features])\n",
    "    \n",
    "    # Cumulative explained variance\n",
    "    cumulative_variance = pca_full.explained_variance_ratio_.cumsum()\n",
    "    \n",
    "    # Plot cumulative explained variance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')\n",
    "    plt.title(\"Cumulative Explained Variance by PCA Components\")\n",
    "    plt.xlabel(\"Number of Principal Components\")\n",
    "    plt.ylabel(\"Cumulative Explained Variance\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "c80a3099-a57a-477f-a3ae-6cb689b8c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL\")\n",
    "if PLOT_GRAPHS:\n",
    "    for key, value in groups.items():\n",
    "        for target in target_cols[:-1]:\n",
    "            print(f\"PCA of {key}, and then coloring by {target}\")\n",
    "            X_features = convert_group_to_dummies(nepal_df, value[0])\n",
    "\n",
    "            pca_2d = PCA(n_components=2)\n",
    "            pca_2d_result = pca_2d.fit_transform(nepal_df[X_features])\n",
    "            #kmeans = KMeans(n_clusters=groups_k[key], random_state=42)\n",
    "            #kmeans_result = kmeans.fit_predict(nepal_df[X_features])\n",
    "            #kmeans_labels = kmeans.labels_\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.scatter(pca_2d_result[:, 0], pca_2d_result[:, 1], c=nepal_df[target], cmap='viridis', alpha=0.6)\n",
    "            plt.title(f\"PCA of {key}, and then coloring by {target}\")\n",
    "            plt.xlabel(\"Principal Component 1\")\n",
    "            plt.ylabel(\"Principal Component 2\")\n",
    "            name = parse_feature_metadata(target)['name']\n",
    "            plt.colorbar(label=f\"{name}\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            \n",
    "            #for target in target_features:\n",
    "                \n",
    "            #    print_cluster_info_for_target(nepal_df, target, kmeans_labels)\n",
    "\n",
    "        plot_cumulative_explained_variance_for_group_for_pca(nepal_df, key, X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "4534171c-2801-4780-a871-d147c2e6db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENEGAL\n"
     ]
    }
   ],
   "source": [
    "print(\"SENEGAL\")\n",
    "if PLOT_GRAPHS:\n",
    "    for key in groups.keys():\n",
    "        if 'Demographic' in key or 'Self-control' in key:\n",
    "                continue\n",
    "        for target in target_cols[:-1]:\n",
    "            \n",
    "            print(f\"PCA of {key}, and then coloring by {target}\") \n",
    "            X_features = convert_group_to_dummies(senegal_df, groups[key][1])\n",
    "\n",
    "            pca_2d = PCA(n_components=2)\n",
    "            pca_2d_result = pca_2d.fit_transform(senegal_df[X_features])\n",
    "            #kmeans = KMeans(n_clusters=groups_k[key], random_state=42)\n",
    "            #kmeans_result = kmeans.fit_predict(senegal_df[X_features])\n",
    "            #kmeans_labels = kmeans.labels_\n",
    "\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.scatter(pca_2d_result[:, 0], pca_2d_result[:, 1], c=senegal_df[target], cmap='viridis', alpha=0.6)\n",
    "            plt.title(f\"PCA of {key}, and then coloring by {target}\")\n",
    "            plt.xlabel(\"Principal Component 1\")\n",
    "            plt.ylabel(\"Principal Component 2\")\n",
    "            name = parse_feature_metadata(target)['name']\n",
    "            plt.colorbar(label=f\"{name}\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            \n",
    "            #for target in target_features:\n",
    "                \n",
    "            #    print_cluster_info_for_target(senegal_df, target, kmeans_labels)\n",
    "\n",
    "            plot_cumulative_explained_variance_for_group_for_pca(senegal_df, key, X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "e3621d8f-723d-46de-95fa-844db2d7d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "7ed02c2d-6685-46e7-8f59-d3ec8aa81d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_explained_variance_for_group_for_kpca(df, group_name, group_features):\n",
    "    num_of_components = min(len(group_features),10)\n",
    "    \n",
    "    # Perform PCA with additional components\n",
    "    kpca_full = KernelPCA(\n",
    "                            n_components=num_of_components,     # how many principal axes you want\n",
    "                            kernel=\"rbf\",       # \"rbf\", \"poly\", \"sigmoid\", \"cosine\", etc.\n",
    "                            gamma=0.1,          # only for RBF / polynomial kernels\n",
    "                            fit_inverse_transform=False,  # True if you want to map back to X-space\n",
    "                            random_state=0\n",
    "                        )\n",
    "    kpca_full_result = kpca_full.fit_transform(df[group_features])\n",
    "    pca_on_kpca = PCA(n_components=num_of_components).fit(kpca_full_result)\n",
    "    \n",
    "    \n",
    "    # Cumulative explained variance\n",
    "    cumulative_variance = pca_on_kpca.explained_variance_ratio_.cumsum()\n",
    "    \n",
    "    # Plot cumulative explained variance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')\n",
    "    plt.title(\"Cumulative Explained Variance by PCA on KPCA Components\")\n",
    "    plt.xlabel(\"Number of Principal Components\")\n",
    "    plt.ylabel(\"Cumulative Explained Variance\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "739533fa-1f3d-42a0-8614-f7cd749226c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEPAL\n"
     ]
    }
   ],
   "source": [
    "print(\"NEPAL\")\n",
    "if PLOT_GRAPHS:\n",
    "    for key, value in groups.items():\n",
    "        print(f\"PCA on {key} -> KPCA on PCA\")\n",
    "        X_features = convert_group_to_dummies(nepal_df, groups[key][0])\n",
    "\n",
    "        # 2. Fit KernelPCA\n",
    "        kpca_2d = KernelPCA(\n",
    "            n_components=2,     # how many principal axes you want\n",
    "            kernel=\"rbf\",       # \"rbf\", \"poly\", \"sigmoid\", \"cosine\", etc.\n",
    "            gamma=0.1,          # only for RBF / polynomial kernels\n",
    "            fit_inverse_transform=False,  # True if you want to map back to X-space\n",
    "            random_state=0\n",
    "        )\n",
    "        kpca_2d_result = kpca_2d.fit_transform(nepal_df[X_features])\n",
    "        #kmeans = KMeans(n_clusters=groups_k[key], random_state=42)\n",
    "        #kmeans_result = kmeans.fit_predict(nepal_df[X_features])\n",
    "        #kmeans_labels = kmeans.labels_\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(kpca_2d_result[:, 0], kpca_2d_result[:, 1], cmap='viridis', alpha=0.6)\n",
    "        plt.title(f\"KPCA Visualization on {key}\")\n",
    "        plt.xlabel(\"Principal Component 1\")\n",
    "        plt.ylabel(\"Principal Component 2\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        #for target in target_features:\n",
    "            \n",
    "        #    print_cluster_info_for_target(nepal_df, target, kmeans_labels)\n",
    "\n",
    "        plot_cumulative_explained_variance_for_group_for_kpca(nepal_df, key, X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "5ffe5501-b4a0-4dd4-80c9-7ef2e9dffab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    for key, value in groups.items():\n",
    "        if 'Demographic' in key or 'Self-control' in key:\n",
    "            continue\n",
    "        \n",
    "        print(f\"PCA on {key} -> KPCA on PCA\")\n",
    "        X_features = convert_group_to_dummies(senegal_df, groups[key][1])\n",
    "\n",
    "        # 2. Fit KernelPCA\n",
    "        kpca_2d = KernelPCA(\n",
    "            n_components=2,     # how many principal axes you want\n",
    "            kernel=\"rbf\",       # \"rbf\", \"poly\", \"sigmoid\", \"cosine\", etc.\n",
    "            gamma=0.1,          # only for RBF / polynomial kernels\n",
    "            fit_inverse_transform=False,  # True if you want to map back to X-space\n",
    "            random_state=0\n",
    "        )\n",
    "        kpca_2d_result = kpca_2d.fit_transform(senegal_df[X_features])\n",
    "        #kmeans = KMeans(n_clusters=groups_k[key], random_state=42)\n",
    "        #kmeans_result = kmeans.fit_predict(senegal_df[X_features])\n",
    "        #kmeans_labels = kmeans.labels_\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(kpca_2d_result[:, 0], kpca_2d_result[:, 1], cmap='viridis', alpha=0.6)\n",
    "        plt.title(f\"KPCA Visualization on {key}\")\n",
    "        plt.xlabel(\"Principal Component 1\")\n",
    "        plt.ylabel(\"Principal Component 2\")\n",
    "        plt.colorbar(label=\"Cluster\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        #for target in target_features:\n",
    "            \n",
    "        #    print_cluster_info_for_target(senegal_df, target, kmeans_labels)\n",
    "\n",
    "        plot_cumulative_explained_variance_for_group_for_kpca(senegal_df, key, X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7038d",
   "metadata": {},
   "source": [
    "# Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "e9cd4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "b96ea705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_info_for_target(df, target_feature, kmeans_labels):\n",
    "    target_name = parse_feature_metadata(target_feature)['name']\n",
    "    for cluster_id in np.unique(kmeans_labels):\n",
    "        indices = np.where(kmeans_labels == cluster_id)\n",
    "        avg_label = np.mean(np.array(df[target_feature])[indices])\n",
    "        print(f\"Cluster {cluster_id}:\\nAverage {target_name} = {avg_label:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "d69de00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_k_inertias(df, group_features):\n",
    "    inertias = []\n",
    "    K = range(1,11)\n",
    "    X_scaled = StandardScaler().fit_transform(df[group_features])\n",
    "    \n",
    "    for k in K:\n",
    "        km = KMeans(n_clusters=k, random_state=0).fit(X_scaled)\n",
    "        inertias.append(km.inertia_)\n",
    "    \n",
    "    plt.plot(K, inertias, '-o')\n",
    "    plt.xlabel('k'); plt.ylabel('Inertia')\n",
    "    plt.title('Elbow Method for Optimal k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "60a70685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_k_sillouhettes(df, group_features):\n",
    "    scores = []\n",
    "    X_scaled = StandardScaler().fit_transform(df[group_features])\n",
    "    \n",
    "    for k in range(2,11):\n",
    "        km = KMeans(n_clusters=k, random_state=0).fit(X_scaled)\n",
    "        labels = km.labels_\n",
    "        scores.append(silhouette_score(X_scaled, labels))\n",
    "    \n",
    "    plt.plot(range(2,11), scores, '-o')\n",
    "    plt.xlabel('k'); plt.ylabel('Avg. Silhouette Score')\n",
    "    plt.title('Silhouette Method for Optimal k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "c1436b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    target_features = convert_group_to_dummies(senegal_df, target_cols)\n",
    "    for key in groups.keys():\n",
    "        if 'Self-control' in key:\n",
    "            continue\n",
    "        print(f\"Group is: {key}\")\n",
    "        X_features = convert_group_to_dummies(senegal_df, groups[key][1])\n",
    "        \n",
    "        plot_k_inertias(senegal_df, X_features)\n",
    "        \n",
    "        plot_k_sillouhettes(senegal_df, X_features)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "710b3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    target_features = convert_group_to_dummies(nepal_df, target_cols)\n",
    "    for key, value in groups.items():\n",
    "        print(f\"Group is: {key}\")\n",
    "        X_features = convert_group_to_dummies(nepal_df, value[0])\n",
    "        \n",
    "        plot_k_inertias(nepal_df, X_features)\n",
    "        \n",
    "        plot_k_sillouhettes(nepal_df, X_features)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "2c286b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_k = {'Geographic Features': 2,\n",
    "          'Demographic Features': 2,\n",
    "          'Hope Features': 2,\n",
    "          'Crop & Fertilizer Features': 3,\n",
    "          'Plot Practice Features': 10,\n",
    "          'Soil Analysis Faetures': 4,\n",
    "          'Plow & Irrigation': 3,\n",
    "          'Self-control Features': 2,\n",
    "          'Household Features': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "12850cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Clustering functions\n",
    "def cluster_kmeans(df, feature_cols, n_clusters=3, random_state=42):\n",
    "    \"\"\"\n",
    "    Run K-Means on df[feature_cols].\n",
    "    Returns: (labels array, fitted KMeans model)\n",
    "    \"\"\"\n",
    "    X = df[feature_cols].to_numpy()\n",
    "    # explicitly set n_init (old default was 10; new “auto” uses smarter init logic)\n",
    "    km = KMeans(n_clusters=n_clusters,\n",
    "                n_init=\"auto\",          # ← explicitly match the old default\n",
    "                random_state=random_state)\n",
    "    labels = km.fit_predict(X)\n",
    "    return labels, km\n",
    "\n",
    "def cluster_agglomerative(df, feature_cols, n_clusters=3):\n",
    "    \"\"\"\n",
    "    Run AgglomerativeClustering on df[feature_cols].\n",
    "    Returns: (labels array, fitted AgglomerativeClustering model)\n",
    "    \"\"\"\n",
    "    X = df[feature_cols].to_numpy()\n",
    "    ag = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    labels = ag.fit_predict(X)\n",
    "    return labels, ag\n",
    "\n",
    "# 3) Profiling function\n",
    "def profile_clusters(df, labels, profiling_features):\n",
    "    \"\"\"\n",
    "    Attach `labels` as df['cluster'], then return:\n",
    "    - cluster sizes (Series)\n",
    "    - mean of productivity_metrics per cluster (DataFrame)\n",
    "    \"\"\"\n",
    "    n = len(profiling_features)\n",
    "    ncols = int(math.ceil(math.sqrt(n)))\n",
    "    nrows = int(math.ceil(n / ncols))\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols,\n",
    "                             figsize=(ncols * 4, nrows * 3),\n",
    "                             squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    \n",
    "    tmp = df.copy()\n",
    "    tmp['cluster'] = labels\n",
    "\n",
    "    for i, feat in enumerate(profiling_features):\n",
    "        ax = axes[i]\n",
    "        sns.boxplot(x=tmp['cluster'].astype(str), y=tmp[feat], ax=ax)\n",
    "        \n",
    "        orig_labels = [lbl.get_text() for lbl in ax.get_xticklabels()]\n",
    "        wrapped_labels = [\"\\n\".join([lab[i:i+30] for i in range(0, len(lab), 30)]) for lab in orig_labels]\n",
    "        \n",
    "        pos = np.arange(len(wrapped_labels))\n",
    "        ax.set_xticks(pos)\n",
    "        ax.set_xticklabels(wrapped_labels, rotation=45,\n",
    "                        ha='right', fontsize=8)\n",
    "\n",
    "        # per-axis label\n",
    "        wrapped_label = \"\\n\".join([feat[i:i+30] for i in range(0, len(feat), 30)])\n",
    "        ax.set_xlabel(wrapped_label, fontsize=8, labelpad=8)\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # turn off leftover axes\n",
    "    for ax in axes[n:]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    # tidy and title\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "1485217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_and_profile(df, country_key, group_name, profiling_feats, cluster_fn):\n",
    "    \n",
    "    cols = groups[group_name][0 if country_key == 'nepal' else 1]\n",
    "    if not cols:\n",
    "        print(f\"Clustering group {group_name} doesnt exist in this country\")\n",
    "        return  # do nothing for groups missing in this country\n",
    "    cols = convert_group_to_dummies(df, cols)\n",
    "    labels, model = cluster_fn(df, cols, n_clusters=3)\n",
    "    print(f\"\\nClustering by: {group_name}\")\n",
    "    profile_clusters(df, labels, profiling_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "98031167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# scikit‐learn KMeans n_init warning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*KMeans is known to have a memory leak.*\",\n",
    "    module=\"sklearn.cluster._kmeans\"\n",
    ")\n",
    "\n",
    "# matplotlib FixedFormatter warning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"FixedFormatter should only be used together with FixedLocator\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "f2498611",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_GRAPHS:\n",
    "    for country_key, df in [('nepal', nepal_df), ('senegal', senegal_df)]:\n",
    "        target_features = convert_group_to_dummies(df, target_cols)\n",
    "        print(f\"\\n===== {country_key.upper()} =====\")\n",
    "        for method_name, cluster_fn in [\n",
    "                ('K-Means', cluster_kmeans),\n",
    "                ('Agglomerative', cluster_agglomerative)\n",
    "            ]:\n",
    "            print(f\"\\n--- {method_name} Clustering by Feature‐Group ---\")\n",
    "            for group_name in groups.keys():\n",
    "                cluster_and_profile(df, country_key, group_name, target_features, cluster_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smallholder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
